{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import transformers\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/skripsi')\n",
        "!ls /content/drive/MyDrive/skripsi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVnzKWiXSwIK",
        "outputId": "f0480ef6-27ae-4a54-fab0-31a03def95e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " app.py\t\t\t\t\t\t   finetuning_RoBERTa3.ipynb\n",
            " check_lang.py\t\t\t\t\t   finetuning_RoBERTa.ipynb\n",
            " cluster_sinta2.ipynb\t\t\t\t   functions.py\n",
            " cluster_sinta3.ipynb\t\t\t\t   model\n",
            " cluster_sinta.ipynb\t\t\t\t   predict_multibert_kmeans_finetuned.ipynb\n",
            "'Copy of cluster_sinta3.ipynb'\t\t\t   predict_RoBERTa_kmeans_finetuned.ipynb\n",
            "'Copy of predict_RoBERTa_kmeans_finetuned.ipynb'   Preprocessing_data_sinta.ipynb\n",
            "'Copy of Untitled0.ipynb'\t\t\t   Preprocessing.py\n",
            " data\t\t\t\t\t\t   __pycache__\n",
            " finetuned_multibert2.ipynb\t\t\t   src\n",
            " finetuned_pipeline.py\t\t\t\t   Untitled0.ipynb\n",
            " finetuning_RoBERTa2.ipynb\t\t\t   Untitled1.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from Preprocessing import preprocess_text"
      ],
      "metadata": {
        "id": "7S4GJ1wV_zz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/skripsi/data/data_sinta_cleaned3.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "id": "XTNmhB6r6Q1Q",
        "outputId": "cdc9b51c-aecd-4baf-a0cf-7456967f26d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      jid                                               desc  \\\n",
              "0       1  Belakangan ini Lembaga PAUD berbondong-bondong...   \n",
              "1       1  The assessment process carried out in schools ...   \n",
              "2       1  Kewajiban guru PAUD untuk memberikan layanan b...   \n",
              "3       1  Pandemi Covid-19 merambah sejak awal tahun 202...   \n",
              "4       1  Dalam upaya mencapai Sustainable Development G...   \n",
              "...   ...                                                ...   \n",
              "8670   12  The purpose of this study to examine the effec...   \n",
              "8671   12  The level of understanding of accounting to be...   \n",
              "8672   12  The purpose of this study was to examine the i...   \n",
              "8673   12  The purpose of this study is to determine the ...   \n",
              "8674   12  ABSTRAK Pelayanan dalam bidang keuangan didaer...   \n",
              "\n",
              "                                                  title        date  \\\n",
              "0     Kemampuan Bahasa Inggris Awal pada Periode Lin...  2023-10-05   \n",
              "1     Strengthening Early Childhood Learning Outcome...  2022-06-09   \n",
              "2     Eksplorasi Deskriptif tentang Layanan Bimbinga...  2023-06-07   \n",
              "3     Perspektif Orang Tua terhadap Pelaksanaan Les ...  2021-06-02   \n",
              "4     Strategi Pencegahan dan Penanganan Stunting Mu...  2023-12-26   \n",
              "...                                                 ...         ...   \n",
              "8670  PENGARUH KINERJA KEUANGAN, DANA ALOKASI UMUM D...  2017-05-15   \n",
              "8671  PENGARUH KECERDASAN EMOSIONAL, KECERDASAN INTE...  2017-08-06   \n",
              "8672  PENGARUH UKURAN PERUSAHAAN, KOMPLEKSITAS OPERA...  2017-02-15   \n",
              "8673  KINERJA DINAS PARIWISATA BALI BERDASARKAN KONS...  2016-11-10   \n",
              "8674  PENGARUH TINGKAT PERPUTARAN PIUTANG, LDR, SPRE...  2013-02-10   \n",
              "\n",
              "                                              journal  \\\n",
              "0     JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI   \n",
              "1     JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI   \n",
              "2     JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI   \n",
              "3     JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI   \n",
              "4     JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI   \n",
              "...                                               ...   \n",
              "8670                               E-JURNAL AKUNTANSI   \n",
              "8671                               E-JURNAL AKUNTANSI   \n",
              "8672                               E-JURNAL AKUNTANSI   \n",
              "8673                               E-JURNAL AKUNTANSI   \n",
              "8674                               E-JURNAL AKUNTANSI   \n",
              "\n",
              "                                           data_cleaned      eissn  jid_umum  \n",
              "0     kemampuan bahasa inggris awal pada periode lin...  2549-8959         1  \n",
              "1     strengthening early childhood learning outcome...  2549-8959         1  \n",
              "2     eksplorasi deskriptif tentang layanan bimbinga...  2549-8959         1  \n",
              "3     perspektif orang tua terhadap pelaksanaan les ...  2549-8959         1  \n",
              "4     strategi pencegahan dan penanganan stunting mu...  2549-8959         1  \n",
              "...                                                 ...        ...       ...  \n",
              "8670  pengaruh kinerja keuangan dana alokasi umum da...  2302-8556        12  \n",
              "8671  pengaruh kecerdasan emosional kecerdasan intel...  2302-8556        12  \n",
              "8672  pengaruh ukuran perusahaan kompleksitas operas...  2302-8556        12  \n",
              "8673  kinerja dinas pariwisata bali berdasarkan kons...  2302-8556        12  \n",
              "8674  pelayanan dalam bidang keuangan didaerah pedes...  2302-8556        12  \n",
              "\n",
              "[8675 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a54b865c-79f1-4703-8e61-35b444d85229\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jid</th>\n",
              "      <th>desc</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>journal</th>\n",
              "      <th>data_cleaned</th>\n",
              "      <th>eissn</th>\n",
              "      <th>jid_umum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Belakangan ini Lembaga PAUD berbondong-bondong...</td>\n",
              "      <td>Kemampuan Bahasa Inggris Awal pada Periode Lin...</td>\n",
              "      <td>2023-10-05</td>\n",
              "      <td>JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI</td>\n",
              "      <td>kemampuan bahasa inggris awal pada periode lin...</td>\n",
              "      <td>2549-8959</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>The assessment process carried out in schools ...</td>\n",
              "      <td>Strengthening Early Childhood Learning Outcome...</td>\n",
              "      <td>2022-06-09</td>\n",
              "      <td>JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI</td>\n",
              "      <td>strengthening early childhood learning outcome...</td>\n",
              "      <td>2549-8959</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Kewajiban guru PAUD untuk memberikan layanan b...</td>\n",
              "      <td>Eksplorasi Deskriptif tentang Layanan Bimbinga...</td>\n",
              "      <td>2023-06-07</td>\n",
              "      <td>JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI</td>\n",
              "      <td>eksplorasi deskriptif tentang layanan bimbinga...</td>\n",
              "      <td>2549-8959</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Pandemi Covid-19 merambah sejak awal tahun 202...</td>\n",
              "      <td>Perspektif Orang Tua terhadap Pelaksanaan Les ...</td>\n",
              "      <td>2021-06-02</td>\n",
              "      <td>JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI</td>\n",
              "      <td>perspektif orang tua terhadap pelaksanaan les ...</td>\n",
              "      <td>2549-8959</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Dalam upaya mencapai Sustainable Development G...</td>\n",
              "      <td>Strategi Pencegahan dan Penanganan Stunting Mu...</td>\n",
              "      <td>2023-12-26</td>\n",
              "      <td>JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI</td>\n",
              "      <td>strategi pencegahan dan penanganan stunting mu...</td>\n",
              "      <td>2549-8959</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8670</th>\n",
              "      <td>12</td>\n",
              "      <td>The purpose of this study to examine the effec...</td>\n",
              "      <td>PENGARUH KINERJA KEUANGAN, DANA ALOKASI UMUM D...</td>\n",
              "      <td>2017-05-15</td>\n",
              "      <td>E-JURNAL AKUNTANSI</td>\n",
              "      <td>pengaruh kinerja keuangan dana alokasi umum da...</td>\n",
              "      <td>2302-8556</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8671</th>\n",
              "      <td>12</td>\n",
              "      <td>The level of understanding of accounting to be...</td>\n",
              "      <td>PENGARUH KECERDASAN EMOSIONAL, KECERDASAN INTE...</td>\n",
              "      <td>2017-08-06</td>\n",
              "      <td>E-JURNAL AKUNTANSI</td>\n",
              "      <td>pengaruh kecerdasan emosional kecerdasan intel...</td>\n",
              "      <td>2302-8556</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8672</th>\n",
              "      <td>12</td>\n",
              "      <td>The purpose of this study was to examine the i...</td>\n",
              "      <td>PENGARUH UKURAN PERUSAHAAN, KOMPLEKSITAS OPERA...</td>\n",
              "      <td>2017-02-15</td>\n",
              "      <td>E-JURNAL AKUNTANSI</td>\n",
              "      <td>pengaruh ukuran perusahaan kompleksitas operas...</td>\n",
              "      <td>2302-8556</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8673</th>\n",
              "      <td>12</td>\n",
              "      <td>The purpose of this study is to determine the ...</td>\n",
              "      <td>KINERJA DINAS PARIWISATA BALI BERDASARKAN KONS...</td>\n",
              "      <td>2016-11-10</td>\n",
              "      <td>E-JURNAL AKUNTANSI</td>\n",
              "      <td>kinerja dinas pariwisata bali berdasarkan kons...</td>\n",
              "      <td>2302-8556</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8674</th>\n",
              "      <td>12</td>\n",
              "      <td>ABSTRAK Pelayanan dalam bidang keuangan didaer...</td>\n",
              "      <td>PENGARUH TINGKAT PERPUTARAN PIUTANG, LDR, SPRE...</td>\n",
              "      <td>2013-02-10</td>\n",
              "      <td>E-JURNAL AKUNTANSI</td>\n",
              "      <td>pelayanan dalam bidang keuangan didaerah pedes...</td>\n",
              "      <td>2302-8556</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8675 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a54b865c-79f1-4703-8e61-35b444d85229')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a54b865c-79f1-4703-8e61-35b444d85229 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a54b865c-79f1-4703-8e61-35b444d85229');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83d8930b-b4b9-477c-94b5-5ea0cb471a33\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83d8930b-b4b9-477c-94b5-5ea0cb471a33')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83d8930b-b4b9-477c-94b5-5ea0cb471a33 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_acfac34a-0e32-4df4-b5aa-64fcf9b94f22\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_acfac34a-0e32-4df4-b5aa-64fcf9b94f22 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8675,\n  \"fields\": [\n    {\n      \"column\": \"jid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          11,\n          10,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"desc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8642,\n        \"samples\": [\n          \"The purpose of this study are to examine differences in market reaction before and after the announcement of the rights issue. Right issue a new share issue carried out by the company which the rights to buy new shares granted to existing shareholders. This research was conducted on all companies listed in Indonesia Stock Exchange 2010-2015 period. The sampling method using purposive sampling. The number of samples of this research were 79 companies. Tests carried out on the sample overall, based on company size, and based on the intended use of funds. The results show the differences in abnormal return before and after the announcement of the rights issue for overall sample and the sample group investment purposes. Results for sample group based on company size and sample group debt payment purposes no differences abnormal return before and after the announcement of rights issue.\",\n          \"Tuberculosis, hereinafter abbreviated as TB, is an infectious disease caused by Mycobacterium tuberculosis, which can attack the lungs and other organs. lungs) such as the pleura, lymph nodes, bones, and other extra-pulmonary organs.2 TB disease is caused by the bacterium Mycobacterium Tuberculosis, this bacterium is rod-shaped and acid-fast, so it is also known as Acid-Resistant Bacillus (BTA).2 Sources of transmission are patients with TB smear positive, which can transmit to people around him, especially close contacts. When the patient coughs or sneezes, the patient spreads germs into the air in the form of droplet nuclei. One cough can produce about 3000 phlegm sprinkling. A person's transmission power is determined by the number of germs expelled from his lungs. The higher the degree of positivity of the sputum examination results, the more infectious the patient is. The factors that allow a person to be exposed to TB germs are determined by the concentration of splashes in the air and the duration of inhaling the air. This research method is an observational analytical study with a case-control design using a retrospective study approach, namely to analyze the effects of disease or health status at this time and measure the risk factors that influence the incidence of pulmonary TB AFB (+) in the past. The number of samples as many as 90 respondents, with a comparison of cases: control (1:1), conducted by means of interviews and observations. The results of the chi square test showed that there was a relationship between occupancy density (P: 0.027; OR: 3,063), lighting (P: 0.000; OR: 7,429), ventilation area (P: 0.000; OR: 6,329), humidity (P: 0.002; OR). : 4,462), with the incidence of pulmonary TB smear (+). The conclusion is that there is a relationship between environmental risk factors and the incidence of filariasis, so it is necessary to do prevention efforts by reducing risk factors and educating the public about efforts to promote and prevent the transmission of pulmonary TB smear (+).\",\n          \"Program MBKM dipercaya mampu mengasah keterampilan life skills mahasiswa. Tujuan artikel adalah menganalisis implementasi life skills dalam program MBKM berdasarkan persepsi mahasiswa program studi PG PAUD. Penelitian ini merupakan penelitian deskriptif kualitatif. Data primer untuk melihat implementasi life skills menggunakan data Google Form yang dibagikan kepada mahasiswa program studi PG PAUD yang lolos Kampus Mengajar Batch 1 sebanyak 7 orang. Data sekunder diambil dari Instrumen Survei Implementasi MBKM 2021 yang diakses melalui SPADA DIKTI. Pengambilan data dilakukan selama 1 bulan yaitu bulan Desember 2021 yang melibatkan 88 mahasiswa program studi PG PAUD. Subyek dalam penelitian ini berjumlah 7 orang yang lolos Kampus Mengajar Batch 1. Pengumpulan data dilakukan dengan observasi, wawancara dan dokumentasi. Data dikumpulkan, diolah menggunakan teknik pengolahan data kualitatif Miles dan Hubermen. Kesimpulannya implementasi life skills telah sesuai dengan tujuan dan harapan dari program MBKM. Program MBKM merupakan salah satu kegiatan yang sangat mendukung tercapainya pembentukan life skills calon guru PAUD.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8630,\n        \"samples\": [\n          \"Pengembangan Media Interaktif Berbasis Filmora untuk Memfasilitasi Kemampuan Pemahaman Matematis Peserta Didik Kelas 12 SMA/MA\",\n          \"Implementasi Model Pendidikan Karakter Berbasis Tumpe pada Anak Usia Dini\",\n          \"PENGARUH MODEL PEMBELAJARAN THINK PAIR SHARE BERBANTUAN POWER POINT TERHADAP HASIL BELAJAR IPA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1580,\n        \"samples\": [\n          \"2024-11-30\",\n          \"2021-04-09\",\n          \"2017-04-18\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"journal\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"E-JOURNAL OF CULTURAL STUDIES\",\n          \"JURNAL KESEHATAN ANDALAS\",\n          \"JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8638,\n        \"samples\": [\n          \"manajemen laba sebagai pemoderasi pengaruh pengungkapan corporate social responsibility pada kinerja keuangan the purpose of this study was to determine the effect of csr disclosure on the companys financial performance and earnings management as a moderating the effects of csr on financial performance the population used in this research is manufacturing companies listed on the indonesian stock exchange bei in the year  as many as  companies determination of the sample using purposive sampling technique with a sample of  observations data collected through nonparticipant observation method the analysis technique used for the first hypothesis is using linear regression analysis simple and to the second hypothesis using regression analysis moderation based on the analysis found that the disclosure of csr significant positive effect on financial performance proxied by roe this indicates that more extensive disclosure of csr undertaken by the company will further improve financial performance analysis of moderating variables showed that earnings management has no influence of csr on financial performance\",\n          \"gambaran multipatologipasien geriatri di poliklinik khusus geriatri rsup dr m djamil padang periode januari  desember  peningkatan angka harapan hidup menyebabkan umur penduduk usia lanjut lebih panjang sehingga mengalami permasalahan kesehatan yang kompleks seperti multipatologi kondisi multipatologi merupakan keadaan yang sering ditemukan pada usia lanjut dan merupakan salah satu karakteristik pasien geriatri tujuan penelitian ini adalah untuk mengetahui gambaran multipatologi pasien geriatri di poliklinik khusus geriatri rsup dr m djamil padang periode januari sampai desember  penelitian ini bersifat deskriptif dengan desain cross sectional sampel penelitian adalah seluruh pasien geriatri di poliklinik khusus geriatri rsup dr m djamil padang tahun  besar sampel yang memenuhi kriteria penilaian sebanyak  pasien hasil penelitian menunjukkan hipertensi merupakan penyakit kronis yang paling banyak pada usia lanjut pasien geriatri yang paling banyak ditemukan adalah kelompok usia    tahun dan jenis kelamin wanita rerata jumlah penyakit kronis pasien geriatri pada penelitian ini adalah  penyakit\",\n          \"learning obstacle dalam soal pemecahan masalah matematis siswa pada pembelajaran materi bangun ruang sisi datar penelitian ini dimaksudkan untuk mengidentifikasi hambatan belajar yang dihadapi oleh siswa pada materi bangun ruang sisi datar data dipenelitian ini diperoleh melalui tes dan wawancara metode penelitian yang digunakan adalah metode kualitatif dengan pendekatan studi kasus penelitian ini melibatkan  siswa kelas viii di salah satu smpn di kabupaten deli serdang sumatera utara hambatan belajar yang ditemukan dalam penelitian ini bersifat ontogenik dan epistemologis hambatan ontogenik merupakan hambatan belajar yang muncul terkait dengan perkembangan kemampuan berpikir siswa hambatan belajar ini bisa diakibatkan oleh ketidaksesuaian pembelajaran atau pengetahuan yang hendak dikonstruksikan oleh siswa dengan kemampuan berpikirnya sedangkan hambatan epistemologis merupakan hambatan yang terjadi akibat keterbatasan pemahaman konsep yang dimiliki oleh siswa siswa hanya memahami konsep secara parsial sehingga siswa mengalami kesulitan saat dihadapkan pada konteks yang berbeda\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eissn\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"2338-2449\",\n          \"2615-1138\",\n          \"2549-8959\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jid_umum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          11,\n          10,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df.data_cleaned.isna()]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "X6DebmrJ6aJj",
        "outputId": "12de934e-cc8a-4393-d3c7-890381e19247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [jid, desc, title, date, journal, data_cleaned, eissn, jid_umum]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b027ae42-cfe4-4ce8-b3a7-3ee335c10f95\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jid</th>\n",
              "      <th>desc</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>journal</th>\n",
              "      <th>data_cleaned</th>\n",
              "      <th>eissn</th>\n",
              "      <th>jid_umum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b027ae42-cfe4-4ce8-b3a7-3ee335c10f95')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b027ae42-cfe4-4ce8-b3a7-3ee335c10f95 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b027ae42-cfe4-4ce8-b3a7-3ee335c10f95');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "title_unik = list(df.journal.unique())\n",
        "title_unik"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opAGPNjF6c5w",
        "outputId": "92473561-1d05-423c-a5dd-09d225724a33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI',\n",
              " 'JURNAL CENDEKIA : JURNAL PENDIDIKAN MATEMATIKA',\n",
              " 'INTERNATIONAL JOURNAL OF ELEMENTARY EDUCATION',\n",
              " 'JURNAL BISNIS DAN AKUNTANSI',\n",
              " 'JURNAL AKUNTANSI DAN KEUANGAN',\n",
              " 'JURNAL PENDIDIKAN TEKNIK MESIN UNDIKSHA',\n",
              " 'INTERNATIONAL JOURNAL OF BASIC AND APPLIED SCIENCE',\n",
              " 'JURNAL KESEHATAN MASYARAKAT',\n",
              " 'GADJAH MADA INTERNATIONAL JOURNAL OF BUSINESS',\n",
              " 'JURNAL KESEHATAN ANDALAS',\n",
              " 'E-JOURNAL OF CULTURAL STUDIES',\n",
              " 'E-JURNAL AKUNTANSI']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.data_cleaned[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "aG0we7V16f0K",
        "outputId": "16e85700-1d3b-4b29-824c-55a289ff00cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'kemampuan bahasa inggris awal pada periode linguistik anak usia dini belakangan ini lembaga paud berbondongbondong memberikan pembelajaran bahasa inggris bagi anak diperiode linguistik penelitian ini bertujuan untuk mengetahui kemampuan awal anak dalam mendengarkan dan mengucapkan kosakata bahasa inggris pada periode linguistic penelitian ini merupakan penelitian deskriptif dengan menggunakan pendekatan kuantitatif populasi penelitian ini mencakup anak pada taman kanakkanak selanjutnya peneliti melakukan penarikan sampling dengan teknik sampling jenuh dengan jumlah  anak penelitian ini dilakukan pada bulan september   maret  dengan bekerjasama dengan guru kelas kegiatan pengumpulan data penelitian ini dilakukan melalui observasi dengan model partisipatif adapun deskripsi hasil penelitian ini dibagi menjadi dua yakni kemampuan mendengarkan kosakata bahasa inggris awal yakni dengan kategori mulai berkembang selanjutnya kemampuan mengucapkan kosakata bahasa inggris awal berada pada kategori mulai berkembang lebih lanjut hasil penelitian ini dapat dijadikan sebagai pijakan dasar menentukan strategi apa yang akan dilakukan untuk melejitkan kemampuan awal bahasa inggris anak dalam periode linguistik'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['jid_umum'] = df['jid']\n",
        "df['jid_umum'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdOvdXfA6jEh",
        "outputId": "2ed30876-5b69-479f-f870-e4085606113d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "journal_id = {title_unik[i] : i + 1 for i in range(len(title_unik))}\n",
        "df['jid'] = df.journal.apply(lambda x : journal_id[x])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 961
        },
        "id": "uR2MHYU36lrI",
        "outputId": "2e49db4a-b102-4889-b4a7-e66813ad6971"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      jid                                               desc  \\\n",
              "0       1  Belakangan ini Lembaga PAUD berbondong-bondong...   \n",
              "1       1  The assessment process carried out in schools ...   \n",
              "2       1  Kewajiban guru PAUD untuk memberikan layanan b...   \n",
              "3       1  Pandemi Covid-19 merambah sejak awal tahun 202...   \n",
              "4       1  Dalam upaya mencapai Sustainable Development G...   \n",
              "...   ...                                                ...   \n",
              "8670   12  The purpose of this study to examine the effec...   \n",
              "8671   12  The level of understanding of accounting to be...   \n",
              "8672   12  The purpose of this study was to examine the i...   \n",
              "8673   12  The purpose of this study is to determine the ...   \n",
              "8674   12  ABSTRAK Pelayanan dalam bidang keuangan didaer...   \n",
              "\n",
              "                                                  title        date  \\\n",
              "0     Kemampuan Bahasa Inggris Awal pada Periode Lin...  2023-10-05   \n",
              "1     Strengthening Early Childhood Learning Outcome...  2022-06-09   \n",
              "2     Eksplorasi Deskriptif tentang Layanan Bimbinga...  2023-06-07   \n",
              "3     Perspektif Orang Tua terhadap Pelaksanaan Les ...  2021-06-02   \n",
              "4     Strategi Pencegahan dan Penanganan Stunting Mu...  2023-12-26   \n",
              "...                                                 ...         ...   \n",
              "8670  PENGARUH KINERJA KEUANGAN, DANA ALOKASI UMUM D...  2017-05-15   \n",
              "8671  PENGARUH KECERDASAN EMOSIONAL, KECERDASAN INTE...  2017-08-06   \n",
              "8672  PENGARUH UKURAN PERUSAHAAN, KOMPLEKSITAS OPERA...  2017-02-15   \n",
              "8673  KINERJA DINAS PARIWISATA BALI BERDASARKAN KONS...  2016-11-10   \n",
              "8674  PENGARUH TINGKAT PERPUTARAN PIUTANG, LDR, SPRE...  2013-02-10   \n",
              "\n",
              "                                              journal  \\\n",
              "0     JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI   \n",
              "1     JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI   \n",
              "2     JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI   \n",
              "3     JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI   \n",
              "4     JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI   \n",
              "...                                               ...   \n",
              "8670                               E-JURNAL AKUNTANSI   \n",
              "8671                               E-JURNAL AKUNTANSI   \n",
              "8672                               E-JURNAL AKUNTANSI   \n",
              "8673                               E-JURNAL AKUNTANSI   \n",
              "8674                               E-JURNAL AKUNTANSI   \n",
              "\n",
              "                                           data_cleaned      eissn  jid_umum  \n",
              "0     kemampuan bahasa inggris awal pada periode lin...  2549-8959         1  \n",
              "1     strengthening early childhood learning outcome...  2549-8959         1  \n",
              "2     eksplorasi deskriptif tentang layanan bimbinga...  2549-8959         1  \n",
              "3     perspektif orang tua terhadap pelaksanaan les ...  2549-8959         1  \n",
              "4     strategi pencegahan dan penanganan stunting mu...  2549-8959         1  \n",
              "...                                                 ...        ...       ...  \n",
              "8670  pengaruh kinerja keuangan dana alokasi umum da...  2302-8556        12  \n",
              "8671  pengaruh kecerdasan emosional kecerdasan intel...  2302-8556        12  \n",
              "8672  pengaruh ukuran perusahaan kompleksitas operas...  2302-8556        12  \n",
              "8673  kinerja dinas pariwisata bali berdasarkan kons...  2302-8556        12  \n",
              "8674  pelayanan dalam bidang keuangan didaerah pedes...  2302-8556        12  \n",
              "\n",
              "[8675 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f201ed5-96a3-401f-b57b-2fd19ece1cef\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>jid</th>\n",
              "      <th>desc</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>journal</th>\n",
              "      <th>data_cleaned</th>\n",
              "      <th>eissn</th>\n",
              "      <th>jid_umum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Belakangan ini Lembaga PAUD berbondong-bondong...</td>\n",
              "      <td>Kemampuan Bahasa Inggris Awal pada Periode Lin...</td>\n",
              "      <td>2023-10-05</td>\n",
              "      <td>JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI</td>\n",
              "      <td>kemampuan bahasa inggris awal pada periode lin...</td>\n",
              "      <td>2549-8959</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>The assessment process carried out in schools ...</td>\n",
              "      <td>Strengthening Early Childhood Learning Outcome...</td>\n",
              "      <td>2022-06-09</td>\n",
              "      <td>JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI</td>\n",
              "      <td>strengthening early childhood learning outcome...</td>\n",
              "      <td>2549-8959</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Kewajiban guru PAUD untuk memberikan layanan b...</td>\n",
              "      <td>Eksplorasi Deskriptif tentang Layanan Bimbinga...</td>\n",
              "      <td>2023-06-07</td>\n",
              "      <td>JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI</td>\n",
              "      <td>eksplorasi deskriptif tentang layanan bimbinga...</td>\n",
              "      <td>2549-8959</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Pandemi Covid-19 merambah sejak awal tahun 202...</td>\n",
              "      <td>Perspektif Orang Tua terhadap Pelaksanaan Les ...</td>\n",
              "      <td>2021-06-02</td>\n",
              "      <td>JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI</td>\n",
              "      <td>perspektif orang tua terhadap pelaksanaan les ...</td>\n",
              "      <td>2549-8959</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Dalam upaya mencapai Sustainable Development G...</td>\n",
              "      <td>Strategi Pencegahan dan Penanganan Stunting Mu...</td>\n",
              "      <td>2023-12-26</td>\n",
              "      <td>JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI</td>\n",
              "      <td>strategi pencegahan dan penanganan stunting mu...</td>\n",
              "      <td>2549-8959</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8670</th>\n",
              "      <td>12</td>\n",
              "      <td>The purpose of this study to examine the effec...</td>\n",
              "      <td>PENGARUH KINERJA KEUANGAN, DANA ALOKASI UMUM D...</td>\n",
              "      <td>2017-05-15</td>\n",
              "      <td>E-JURNAL AKUNTANSI</td>\n",
              "      <td>pengaruh kinerja keuangan dana alokasi umum da...</td>\n",
              "      <td>2302-8556</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8671</th>\n",
              "      <td>12</td>\n",
              "      <td>The level of understanding of accounting to be...</td>\n",
              "      <td>PENGARUH KECERDASAN EMOSIONAL, KECERDASAN INTE...</td>\n",
              "      <td>2017-08-06</td>\n",
              "      <td>E-JURNAL AKUNTANSI</td>\n",
              "      <td>pengaruh kecerdasan emosional kecerdasan intel...</td>\n",
              "      <td>2302-8556</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8672</th>\n",
              "      <td>12</td>\n",
              "      <td>The purpose of this study was to examine the i...</td>\n",
              "      <td>PENGARUH UKURAN PERUSAHAAN, KOMPLEKSITAS OPERA...</td>\n",
              "      <td>2017-02-15</td>\n",
              "      <td>E-JURNAL AKUNTANSI</td>\n",
              "      <td>pengaruh ukuran perusahaan kompleksitas operas...</td>\n",
              "      <td>2302-8556</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8673</th>\n",
              "      <td>12</td>\n",
              "      <td>The purpose of this study is to determine the ...</td>\n",
              "      <td>KINERJA DINAS PARIWISATA BALI BERDASARKAN KONS...</td>\n",
              "      <td>2016-11-10</td>\n",
              "      <td>E-JURNAL AKUNTANSI</td>\n",
              "      <td>kinerja dinas pariwisata bali berdasarkan kons...</td>\n",
              "      <td>2302-8556</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8674</th>\n",
              "      <td>12</td>\n",
              "      <td>ABSTRAK Pelayanan dalam bidang keuangan didaer...</td>\n",
              "      <td>PENGARUH TINGKAT PERPUTARAN PIUTANG, LDR, SPRE...</td>\n",
              "      <td>2013-02-10</td>\n",
              "      <td>E-JURNAL AKUNTANSI</td>\n",
              "      <td>pelayanan dalam bidang keuangan didaerah pedes...</td>\n",
              "      <td>2302-8556</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8675 rows Ã— 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f201ed5-96a3-401f-b57b-2fd19ece1cef')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2f201ed5-96a3-401f-b57b-2fd19ece1cef button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2f201ed5-96a3-401f-b57b-2fd19ece1cef');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ec3b18c-2190-4d13-8ed5-22eb85fd984f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ec3b18c-2190-4d13-8ed5-22eb85fd984f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ec3b18c-2190-4d13-8ed5-22eb85fd984f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_c16e1850-5401-46d2-8323-70581e3c4c92\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_c16e1850-5401-46d2-8323-70581e3c4c92 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8675,\n  \"fields\": [\n    {\n      \"column\": \"jid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          11,\n          10,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"desc\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8642,\n        \"samples\": [\n          \"The purpose of this study are to examine differences in market reaction before and after the announcement of the rights issue. Right issue a new share issue carried out by the company which the rights to buy new shares granted to existing shareholders. This research was conducted on all companies listed in Indonesia Stock Exchange 2010-2015 period. The sampling method using purposive sampling. The number of samples of this research were 79 companies. Tests carried out on the sample overall, based on company size, and based on the intended use of funds. The results show the differences in abnormal return before and after the announcement of the rights issue for overall sample and the sample group investment purposes. Results for sample group based on company size and sample group debt payment purposes no differences abnormal return before and after the announcement of rights issue.\",\n          \"Tuberculosis, hereinafter abbreviated as TB, is an infectious disease caused by Mycobacterium tuberculosis, which can attack the lungs and other organs. lungs) such as the pleura, lymph nodes, bones, and other extra-pulmonary organs.2 TB disease is caused by the bacterium Mycobacterium Tuberculosis, this bacterium is rod-shaped and acid-fast, so it is also known as Acid-Resistant Bacillus (BTA).2 Sources of transmission are patients with TB smear positive, which can transmit to people around him, especially close contacts. When the patient coughs or sneezes, the patient spreads germs into the air in the form of droplet nuclei. One cough can produce about 3000 phlegm sprinkling. A person's transmission power is determined by the number of germs expelled from his lungs. The higher the degree of positivity of the sputum examination results, the more infectious the patient is. The factors that allow a person to be exposed to TB germs are determined by the concentration of splashes in the air and the duration of inhaling the air. This research method is an observational analytical study with a case-control design using a retrospective study approach, namely to analyze the effects of disease or health status at this time and measure the risk factors that influence the incidence of pulmonary TB AFB (+) in the past. The number of samples as many as 90 respondents, with a comparison of cases: control (1:1), conducted by means of interviews and observations. The results of the chi square test showed that there was a relationship between occupancy density (P: 0.027; OR: 3,063), lighting (P: 0.000; OR: 7,429), ventilation area (P: 0.000; OR: 6,329), humidity (P: 0.002; OR). : 4,462), with the incidence of pulmonary TB smear (+). The conclusion is that there is a relationship between environmental risk factors and the incidence of filariasis, so it is necessary to do prevention efforts by reducing risk factors and educating the public about efforts to promote and prevent the transmission of pulmonary TB smear (+).\",\n          \"Program MBKM dipercaya mampu mengasah keterampilan life skills mahasiswa. Tujuan artikel adalah menganalisis implementasi life skills dalam program MBKM berdasarkan persepsi mahasiswa program studi PG PAUD. Penelitian ini merupakan penelitian deskriptif kualitatif. Data primer untuk melihat implementasi life skills menggunakan data Google Form yang dibagikan kepada mahasiswa program studi PG PAUD yang lolos Kampus Mengajar Batch 1 sebanyak 7 orang. Data sekunder diambil dari Instrumen Survei Implementasi MBKM 2021 yang diakses melalui SPADA DIKTI. Pengambilan data dilakukan selama 1 bulan yaitu bulan Desember 2021 yang melibatkan 88 mahasiswa program studi PG PAUD. Subyek dalam penelitian ini berjumlah 7 orang yang lolos Kampus Mengajar Batch 1. Pengumpulan data dilakukan dengan observasi, wawancara dan dokumentasi. Data dikumpulkan, diolah menggunakan teknik pengolahan data kualitatif Miles dan Hubermen. Kesimpulannya implementasi life skills telah sesuai dengan tujuan dan harapan dari program MBKM. Program MBKM merupakan salah satu kegiatan yang sangat mendukung tercapainya pembentukan life skills calon guru PAUD.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8630,\n        \"samples\": [\n          \"Pengembangan Media Interaktif Berbasis Filmora untuk Memfasilitasi Kemampuan Pemahaman Matematis Peserta Didik Kelas 12 SMA/MA\",\n          \"Implementasi Model Pendidikan Karakter Berbasis Tumpe pada Anak Usia Dini\",\n          \"PENGARUH MODEL PEMBELAJARAN THINK PAIR SHARE BERBANTUAN POWER POINT TERHADAP HASIL BELAJAR IPA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1580,\n        \"samples\": [\n          \"2024-11-30\",\n          \"2021-04-09\",\n          \"2017-04-18\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"journal\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"E-JOURNAL OF CULTURAL STUDIES\",\n          \"JURNAL KESEHATAN ANDALAS\",\n          \"JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8638,\n        \"samples\": [\n          \"manajemen laba sebagai pemoderasi pengaruh pengungkapan corporate social responsibility pada kinerja keuangan the purpose of this study was to determine the effect of csr disclosure on the companys financial performance and earnings management as a moderating the effects of csr on financial performance the population used in this research is manufacturing companies listed on the indonesian stock exchange bei in the year  as many as  companies determination of the sample using purposive sampling technique with a sample of  observations data collected through nonparticipant observation method the analysis technique used for the first hypothesis is using linear regression analysis simple and to the second hypothesis using regression analysis moderation based on the analysis found that the disclosure of csr significant positive effect on financial performance proxied by roe this indicates that more extensive disclosure of csr undertaken by the company will further improve financial performance analysis of moderating variables showed that earnings management has no influence of csr on financial performance\",\n          \"gambaran multipatologipasien geriatri di poliklinik khusus geriatri rsup dr m djamil padang periode januari  desember  peningkatan angka harapan hidup menyebabkan umur penduduk usia lanjut lebih panjang sehingga mengalami permasalahan kesehatan yang kompleks seperti multipatologi kondisi multipatologi merupakan keadaan yang sering ditemukan pada usia lanjut dan merupakan salah satu karakteristik pasien geriatri tujuan penelitian ini adalah untuk mengetahui gambaran multipatologi pasien geriatri di poliklinik khusus geriatri rsup dr m djamil padang periode januari sampai desember  penelitian ini bersifat deskriptif dengan desain cross sectional sampel penelitian adalah seluruh pasien geriatri di poliklinik khusus geriatri rsup dr m djamil padang tahun  besar sampel yang memenuhi kriteria penilaian sebanyak  pasien hasil penelitian menunjukkan hipertensi merupakan penyakit kronis yang paling banyak pada usia lanjut pasien geriatri yang paling banyak ditemukan adalah kelompok usia    tahun dan jenis kelamin wanita rerata jumlah penyakit kronis pasien geriatri pada penelitian ini adalah  penyakit\",\n          \"learning obstacle dalam soal pemecahan masalah matematis siswa pada pembelajaran materi bangun ruang sisi datar penelitian ini dimaksudkan untuk mengidentifikasi hambatan belajar yang dihadapi oleh siswa pada materi bangun ruang sisi datar data dipenelitian ini diperoleh melalui tes dan wawancara metode penelitian yang digunakan adalah metode kualitatif dengan pendekatan studi kasus penelitian ini melibatkan  siswa kelas viii di salah satu smpn di kabupaten deli serdang sumatera utara hambatan belajar yang ditemukan dalam penelitian ini bersifat ontogenik dan epistemologis hambatan ontogenik merupakan hambatan belajar yang muncul terkait dengan perkembangan kemampuan berpikir siswa hambatan belajar ini bisa diakibatkan oleh ketidaksesuaian pembelajaran atau pengetahuan yang hendak dikonstruksikan oleh siswa dengan kemampuan berpikirnya sedangkan hambatan epistemologis merupakan hambatan yang terjadi akibat keterbatasan pemahaman konsep yang dimiliki oleh siswa siswa hanya memahami konsep secara parsial sehingga siswa mengalami kesulitan saat dihadapkan pada konteks yang berbeda\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eissn\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"2338-2449\",\n          \"2615-1138\",\n          \"2549-8959\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jid_umum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 12,\n        \"num_unique_values\": 12,\n        \"samples\": [\n          11,\n          10,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/skripsi/data/data_sinta_cleaned3.csv', index=False)"
      ],
      "metadata": {
        "id": "dVie7GI96stL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1 'JURNAL OBSESI: JURNAL PENDIDIKAN ANAK USIA DINI',\n",
        "2 'JURNAL CENDEKIA : JURNAL PENDIDIKAN MATEMATIKA',\n",
        "3 'INTERNATIONAL JOURNAL OF ELEMENTARY EDUCATION',\n",
        "4 'JURNAL BISNIS DAN AKUNTANSI',\n",
        "5 'JURNAL AKUNTANSI DAN KEUANGAN',\n",
        "6 'JURNAL PENDIDIKAN TEKNIK MESIN UNDIKSHA',\n",
        "7 'INTERNATIONAL JOURNAL OF BASIC AND APPLIED SCIENCE',\n",
        "8 'JURNAL KESEHATAN MASYARAKAT',\n",
        "9 'GADJAH MADA INTERNATIONAL JOURNAL OF BUSINESS',\n",
        "10 'JURNAL KESEHATAN ANDALAS',\n",
        "11 'E-JOURNAL OF CULTURAL STUDIES',\n",
        "12 'E-JURNAL AKUNTANSI'\n",
        " '''\n",
        "\n",
        "\n",
        "jurnal_id = 1\n",
        "\n",
        "\n",
        "data_jid = df[df['jid']==jurnal_id]\n",
        "data = data_jid['data_cleaned']\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "78EKd8Nc8EK2",
        "outputId": "c7e001e2-56f7-4425-dda7-f2e2de56d534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       kemampuan bahasa inggris awal pada periode lin...\n",
              "1       strengthening early childhood learning outcome...\n",
              "2       eksplorasi deskriptif tentang layanan bimbinga...\n",
              "3       perspektif orang tua terhadap pelaksanaan les ...\n",
              "4       strategi pencegahan dan penanganan stunting mu...\n",
              "                              ...                        \n",
              "1464    pencapaian perkembangan anak usia dini di tama...\n",
              "1465    colour ball based on microcontroller as a educ...\n",
              "1466    pengembangan teknologi digital cerita sains te...\n",
              "1467    pengaruh bimtek guru pembimbing khusus terhada...\n",
              "1468    managing english young learners classroom acti...\n",
              "Name: data_cleaned, Length: 1469, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kemampuan bahasa inggris awal pada periode lin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>strengthening early childhood learning outcome...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eksplorasi deskriptif tentang layanan bimbinga...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>perspektif orang tua terhadap pelaksanaan les ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>strategi pencegahan dan penanganan stunting mu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1464</th>\n",
              "      <td>pencapaian perkembangan anak usia dini di tama...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1465</th>\n",
              "      <td>colour ball based on microcontroller as a educ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1466</th>\n",
              "      <td>pengembangan teknologi digital cerita sains te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1467</th>\n",
              "      <td>pengaruh bimtek guru pembimbing khusus terhada...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1468</th>\n",
              "      <td>managing english young learners classroom acti...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1469 rows Ã— 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RobertaClassifier(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(RobertaClassifier, self).__init__()\n",
        "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(self.roberta.config.hidden_size, 300),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(300, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 50),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(50, num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        x = outputs['last_hidden_state']\n",
        "        # x = self.classifier(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "7aWZPMAb8G0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained RoBERTa tokenizer and model\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaClassifier(12)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/skripsi/model/finetuned_model_roberta3.pt'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385,
          "referenced_widgets": [
            "549e78a4233249c2be4925ab10972785",
            "146f85b994664ee6ade54ecd69a228ad",
            "193f59f390a64230bb77c0275684193c",
            "680bee3994844275a0c08bc555a46311",
            "54baf27df5f043fb9fed7804a29c1130",
            "31a5e116a8fb4345897b4d7da863878f",
            "cbc800352b3448199f33632c59295968",
            "b9026ac7bf2f4783ac9764ddafda705f",
            "f201f191345a41a0bcf41315e939e301",
            "3efc8966f0ac4c9383874dc8695a4203",
            "7a441301e03f428483391af53b0776b5",
            "89d801d709fd43338b40d37915bc25a8",
            "546978400ae74f769ffa6938c9519330",
            "031f94d744af4c0f9ea6c24080e16449",
            "2e1525a0f7ca41d9a74be54d9bc1a9c5",
            "8aa790f4c7274754bc1f8ad69bedc869",
            "547ccf5eb23840b48cb34a5ff1c1c12c",
            "c3b5ca83609e499285d2c7a02b8e811b",
            "c30d73c61b434242a34737be1e50c487",
            "a68e69ee46064a8e90463a81df508c57",
            "aea18d8858cc40e09fbc68e0551da708",
            "ed9069916c1a4cf1b5693b4ab86c5c30",
            "908b4dd4a17641c28c13ff81c145f6b2",
            "52ab1dd2b73b49948c290d455bfc00f1",
            "8808959cc4a346e7aa3c2d5665fe0221",
            "f995d686a0cd423d91eddc0bba883d5a",
            "af9aa40682ca4c10903d8091a15995e8",
            "932db13661364d69bd6ef1b830988d6d",
            "2747a6ff520c44cb86db4ed41ef4a6a1",
            "86c5297b3cee45aebf6d4a98639190eb",
            "ac5d70dd1f5e4f7f82cdff36d98a3776",
            "3777b8ad4fd44a42afb8d00e17adfb33",
            "87fbc680170446978e5bdd376401dfc8",
            "9bb16ce060d64e18a8b5065576638194",
            "981f9240bb76423a85f354f77c2e83ce",
            "c1597e445a994bb381c37aef93a64708",
            "3388014d82684a78845e5058174f5930",
            "199a74287aec4cb49ea1a974c667c61c",
            "7b98b3327dad4e89b5acb9e91160fc7f",
            "2d6836e1b7fd4acd9a69d4eb74765f04",
            "e306bef984ae43e7a83c6b11ca63aa2f",
            "cbfcbab16fc44d84994d486b294d8f5d",
            "9ba6a4bfac62442fb1dc71f87e4d44c3",
            "a9b4ba346ddc44578a665daed4ca7502",
            "31608376d9764444a02d602a1d9e2842",
            "b994bf776f9f442a9adbd9d5de79c6ab",
            "308d58cdd8df4233bc7239b1a2b7dae1",
            "9ba9ea4ce63f47e0957f4ab19dcb11d4",
            "9df96911ee5343449442391529539b96",
            "986c49bc9d774eea8a78af7ad498e3f0",
            "8339a54fb327497fa950fc9bdbc6286b",
            "cd98c4cd16314dd5ac9fedc38f47a285",
            "391ed6f18e52470a8dab64159cb9c9fe",
            "fc8b632e81de4a959fd032d43a54a7fa",
            "48fee6dc0a4043fcb85ac47f6895a78c",
            "5e10cc7fe1de42ed9e280cdf34233fc5",
            "0387c9a275fe4495ae4d6e866d6b6247",
            "de476d0cba9742d09041b3491e950f12",
            "56b6bba97ddb47efa9666b7985d11fe3",
            "8881388a0b2a4e47b60254486852ac97",
            "4ff9ef2d39b34e6eaaf567655365820d",
            "0573830ebf9e49cc9597026103111104",
            "d96934f18f724573aa4467cdcd11c507",
            "c26788e8407042c59b8cff0382a50757",
            "b295d763b05548c694e99b191e89c1bf",
            "c3e0261c6289472eac5a9261a7e50096"
          ]
        },
        "id": "VvfnfEJD8ImI",
        "outputId": "047cbb68-cf54-45e7-a4be-ceec5424fa57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "549e78a4233249c2be4925ab10972785"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "89d801d709fd43338b40d37915bc25a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "908b4dd4a17641c28c13ff81c145f6b2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bb16ce060d64e18a8b5065576638194"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "31608376d9764444a02d602a1d9e2842"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e10cc7fe1de42ed9e280cdf34233fc5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_data(texts, tokenizer, max_length=128):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded_dict = tokenizer.encode_plus(\n",
        "                            text,\n",
        "                            add_special_tokens=True,\n",
        "                            max_length=max_length,\n",
        "                            pad_to_max_length=True,\n",
        "                            return_attention_mask=True,\n",
        "                            return_tensors='pt'\n",
        "                       )\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks\n",
        "\n",
        "# Tokenize data\n",
        "input_ids, attention_masks = tokenize_data(data, tokenizer)"
      ],
      "metadata": {
        "id": "DU61BYl88LjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0442e539-f3cd-4d44-9667-6c2d645cf7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloader\n",
        "class ArticleDataset(Dataset):\n",
        "    def __init__(self, input_ids, attention_masks):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.input_ids[idx],\n",
        "            'attention_mask': self.attention_masks[idx]\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids)\n",
        "\n",
        "dataset = ArticleDataset(input_ids, attention_masks)\n"
      ],
      "metadata": {
        "id": "N2fHzwsaCBVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloader\n",
        "batch_size = 32\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "o2QtM_QSCHNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "if torch.cuda.is_available():\n",
        "    device = 'cuda'\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "# Set model to evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "LiPrwYsUQfVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315b97d6-0ef7-48f5-980e-0a5d2495af9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaClassifier(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=300, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=300, out_features=100, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=50, out_features=12, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Embedding\n",
        "embeddings = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        embeddings.append(outputs.cpu().numpy())\n",
        "\n",
        "embeddings = np.concatenate(embeddings, axis=0)"
      ],
      "metadata": {
        "id": "MQ4pc8d3Qm6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "id": "TSdEZ_l_Ulkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2de0050d-4290-4900-e238-51459569b9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1469, 128, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0][0]"
      ],
      "metadata": {
        "id": "k77Mfs-mUpe9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56f71ac8-832f-4248-fdcc-d95853306435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.23403561e+00,  1.01779139e+00,  4.26087320e-01, -5.99910438e-01,\n",
              "        6.64480984e-01, -2.56899047e+00,  7.49779820e-01,  9.18821633e-01,\n",
              "       -7.02672541e-01,  7.90182590e-01, -1.00123250e+00, -1.21075809e+00,\n",
              "       -2.77516823e-02, -5.29252827e-01,  2.80066997e-01, -1.17970645e+00,\n",
              "       -9.52779472e-01,  2.27648437e-01, -6.72499061e-01, -4.23830867e-01,\n",
              "        2.02610403e-01, -4.65502620e-01,  4.30165917e-01,  1.61578786e+00,\n",
              "       -3.74300778e-01,  6.94424689e-01,  6.10286713e-01, -4.48639065e-01,\n",
              "        3.20791483e-01,  4.91590440e-01, -1.43837416e+00,  1.57407761e-01,\n",
              "        1.57301977e-01,  6.64121628e-01, -5.78664243e-01,  2.50722110e-01,\n",
              "        3.99284028e-02, -5.78637719e-02, -7.53799617e-01, -5.91877103e-01,\n",
              "        2.35589504e+00,  6.38225615e-01,  4.35148180e-02,  5.67160785e-01,\n",
              "       -5.12719691e-01, -7.89658129e-01,  1.70293748e-01, -5.97165644e-01,\n",
              "        3.25357877e-02,  9.99962449e-01, -1.07520990e-01, -6.20456755e-01,\n",
              "       -3.99902225e-01,  5.07609010e-01,  4.50210065e-01, -1.45066500e-01,\n",
              "        1.77387685e-01, -4.33618039e-01, -5.95963597e-01, -8.78856897e-01,\n",
              "        6.91080511e-01, -9.77582693e-01, -4.24152285e-01,  9.95221019e-01,\n",
              "        9.44601774e-01, -3.24185550e-01, -4.81027603e-01, -2.46494263e-01,\n",
              "       -1.63460064e+00,  1.28032446e+00, -2.73164898e-01,  1.44795763e+00,\n",
              "       -5.84868789e-01, -1.30224955e+00,  4.38785225e-01,  5.76987624e-01,\n",
              "       -1.06536424e+00, -1.77177370e+00,  7.17958033e-01,  3.47784936e-01,\n",
              "       -6.52216852e-01, -2.11262122e-01, -8.28572750e-01, -8.23772132e-01,\n",
              "        3.87861639e-01, -3.17309558e-01,  1.13453519e+00,  9.74391639e-01,\n",
              "        3.76892328e-01,  1.51732624e-01, -4.39295545e-02, -2.47726575e-01,\n",
              "       -8.11289132e-01,  2.35085845e-01, -3.16395968e-01,  4.93697792e-01,\n",
              "        4.48967487e-01, -2.53500032e+00,  3.54719788e-01,  4.86107618e-01,\n",
              "       -8.17292213e-01,  2.51359846e-02,  2.58848023e+00, -7.39994586e-01,\n",
              "        4.79214549e-01,  6.37119353e-01, -4.79079425e-01,  3.54993939e-01,\n",
              "       -6.57036066e-01, -9.05637324e-01, -2.24195749e-01, -2.69284278e-01,\n",
              "        8.39489639e-01, -1.54068917e-01,  6.32091224e-01,  3.09421748e-01,\n",
              "       -1.49854827e+00, -2.54786402e-01, -7.28998408e-02,  8.04223001e-01,\n",
              "       -7.57235169e-01,  8.76918733e-01,  1.28430462e+00, -3.46008509e-01,\n",
              "       -3.09288383e-01, -6.03313208e-01, -2.94163406e-01, -6.42702639e-01,\n",
              "       -2.69602209e-01,  7.69104600e-01,  7.10855305e-01, -1.62905502e+00,\n",
              "        8.28415871e-01,  1.71393633e+00,  6.98217809e-01,  6.51791632e-01,\n",
              "        3.35910954e-02, -1.03456795e+00,  1.32937706e+00, -4.94966805e-01,\n",
              "       -7.64624178e-01,  2.97662795e-01,  1.89017808e+00, -1.62257493e-01,\n",
              "        1.78241158e+00, -8.20992947e-01, -1.54323295e-01,  1.15550947e+00,\n",
              "        6.04501426e-01, -9.40203428e-01, -3.69850397e-02, -3.44832033e-01,\n",
              "        7.21589267e-01, -4.20818418e-01, -1.20247948e+00, -5.07644832e-01,\n",
              "       -8.62705767e-01,  1.03243506e+00, -4.60905790e-01,  1.90437675e+00,\n",
              "       -5.03050804e-01, -6.36434138e-01, -3.55217844e-01, -6.52703583e-01,\n",
              "        2.53194124e-01, -2.90989369e-01,  7.56530225e-01, -1.45473434e-02,\n",
              "        6.70392632e-01,  7.42711008e-01, -5.69590390e-01, -9.53370452e-01,\n",
              "       -6.59294188e-01,  6.14824116e-01,  6.18552677e-02,  1.63542593e+00,\n",
              "        6.61626697e-01,  1.33763957e+00,  9.89906251e-01, -4.05676365e-01,\n",
              "        1.90395400e-01,  2.55178899e-01,  6.25764728e-01, -2.75061186e-02,\n",
              "       -3.55809093e-01,  8.10042500e-01,  6.10714555e-01, -1.18788714e-02,\n",
              "       -9.33790386e-01,  5.34792960e-01,  1.79922962e+00,  5.64936817e-01,\n",
              "        5.78734159e-01,  4.27520901e-01, -7.82184958e-01,  2.89087176e-01,\n",
              "       -3.53039265e-01, -1.61425725e-01,  2.21575931e-01,  2.90713161e-01,\n",
              "       -1.06896329e+00,  3.78984287e-02, -2.94130802e-01, -6.67109609e-01,\n",
              "       -1.49551857e+00, -3.79101366e-01,  9.36780646e-02,  3.09344172e-01,\n",
              "       -5.70798874e-01,  7.89314330e-01, -5.84989786e-01, -1.43404678e-01,\n",
              "       -5.68014324e-01, -1.44213021e+00,  8.64386335e-02,  2.06546292e-01,\n",
              "        2.54972577e-02,  1.64967155e+00,  3.64284605e-01,  1.12202144e+00,\n",
              "       -8.58116969e-02,  1.29018831e+00, -1.64211309e+00,  1.25757337e+00,\n",
              "       -1.08104562e-02, -1.28560305e+00,  2.31915519e-01, -1.27188593e-01,\n",
              "       -4.56300527e-01,  1.44388902e+00,  5.15845895e-01, -1.24461241e-01,\n",
              "       -7.77135342e-02,  6.71497881e-01,  1.74368303e-02, -2.25925851e+00,\n",
              "       -5.35046123e-02,  8.13648701e-02, -6.77745581e-01, -1.05426455e+00,\n",
              "       -2.10750914e+00,  4.58097667e-01,  6.67320311e-01,  2.37321481e-01,\n",
              "        2.99866032e-02,  1.12305224e-01,  4.05951679e-01,  4.66253571e-02,\n",
              "       -1.92970252e+00, -7.47327566e-01, -7.74356663e-01,  7.25037217e-01,\n",
              "       -2.96241432e-01, -2.44746342e-01, -8.58480155e-01,  2.81004250e-01,\n",
              "       -2.90759534e-01, -1.26867682e-01, -1.29543602e-01,  5.52708328e-01,\n",
              "       -1.01216960e+00, -1.78953350e-01,  5.55267513e-01, -2.99961507e-01,\n",
              "       -2.49907658e-01, -6.53130770e-01,  3.98864388e-01,  1.52212560e-01,\n",
              "        4.82127704e-02,  1.22037184e+00, -8.28805387e-01, -3.75510976e-02,\n",
              "        8.04544151e-01, -1.21487416e-01,  2.25596759e-03,  8.88938755e-02,\n",
              "       -1.61502838e+00,  8.44840646e-01,  3.90611559e-01,  8.69251549e-01,\n",
              "       -1.55183867e-01,  1.32383767e-03, -2.35024190e+00, -2.92904109e-01,\n",
              "        1.16423406e-01,  1.03003824e+00,  2.73067594e+00, -3.27403754e-01,\n",
              "       -1.18410385e+00,  3.44799012e-01,  6.18873656e-01, -2.29608700e-01,\n",
              "       -1.06672037e+00,  1.46041960e-01,  3.89432639e-01,  1.42704880e+00,\n",
              "       -3.32421005e-01, -1.07304566e-01, -9.34046328e-01,  6.76295280e-01,\n",
              "        3.78676206e-02, -8.27647150e-01,  2.59981424e-01,  9.69972551e-01,\n",
              "       -1.39011130e-01,  1.03883541e+00,  2.17117608e-01,  4.72311437e-01,\n",
              "       -2.20096380e-01, -3.02516699e-01,  1.15347490e-01,  1.21486831e+00,\n",
              "       -2.22282842e-01,  4.02929783e-01,  7.99682260e-01,  1.24143876e-01,\n",
              "        1.82283914e+00,  2.72649616e-01, -1.67292804e-02,  1.00672054e+00,\n",
              "       -4.33730513e-01,  6.84094369e-01,  6.05652034e-01, -5.07359147e-01,\n",
              "       -2.51201630e-01, -7.50823557e-01,  1.38532937e+00,  1.34998262e+00,\n",
              "        5.52176952e-01, -1.04777813e+00, -1.18267620e+00,  9.06959534e-01,\n",
              "       -7.15142369e-01, -4.55063164e-01,  4.66277540e-01, -6.63491786e-01,\n",
              "        6.38339043e-01, -3.60307962e-01, -4.26749974e-01, -5.14097095e-01,\n",
              "        8.77978742e-01, -5.12596846e-01,  1.76105186e-01,  2.29929984e-01,\n",
              "        6.12430453e-01,  9.82847691e-01,  4.79151696e-01,  1.46095440e-01,\n",
              "       -9.74589884e-01, -1.16561031e+00,  1.40597785e+00, -9.12696123e-01,\n",
              "        1.10890174e+00,  2.90736794e-01, -3.18636388e-01, -6.11138403e-01,\n",
              "        3.38239558e-02,  2.75975734e-01, -6.49354458e-01,  3.05308312e-01,\n",
              "        2.71129394e+00, -4.48418945e-01, -1.61148921e-01,  1.79006624e+00,\n",
              "        3.13906789e-01,  6.19721651e-01, -3.26997310e-01, -1.97289839e-01,\n",
              "        3.39421093e-01,  5.24579763e-01,  1.36239541e+00,  7.29139566e-01,\n",
              "       -3.09328616e-01, -4.83294219e-01,  1.60355330e-01,  4.11660522e-01,\n",
              "       -2.15288147e-01, -6.79528832e-01,  1.45891559e+00, -4.68095899e-01,\n",
              "        5.60551822e-01,  4.92495269e-01, -1.60151601e-01, -4.34961408e-01,\n",
              "        1.23932552e+00,  1.20425487e+00,  9.71504509e-01,  1.56981602e-01,\n",
              "        1.32269609e+00, -4.53758001e-01, -5.64446926e-01,  1.24873519e-01,\n",
              "       -2.10685924e-01, -1.89062372e-01,  2.90522933e-01,  3.00549537e-01,\n",
              "       -1.12746942e+00, -6.56402707e-01, -2.63192475e-01, -1.78059593e-01,\n",
              "        7.47804105e-01, -3.38227272e-01,  3.52973491e-01,  1.40318763e+00,\n",
              "        1.05888224e+00,  3.05948704e-01,  2.61162352e-02,  9.82489705e-01,\n",
              "        1.43903866e-01, -1.38628519e+00, -3.07930168e-03, -9.54332292e-01,\n",
              "        3.92646492e-01, -9.37779844e-01,  8.76029074e-01, -1.09873474e+00,\n",
              "       -7.31907964e-01,  1.31522560e+00,  2.85093427e-01, -2.40228310e-01,\n",
              "        9.13391829e-01,  1.82890907e-01, -4.35598433e-01,  1.24488873e-02,\n",
              "       -2.78521739e-02,  3.90787661e-01,  1.77333367e+00, -6.90738440e-01,\n",
              "        2.68123865e-01, -1.73541293e-01, -1.34040797e+00, -3.21218133e-01,\n",
              "       -9.50751305e-01, -5.61747015e-01,  3.80397499e-01,  7.26340413e-01,\n",
              "        7.90121853e-01,  7.41481662e-01,  1.97548628e+00, -1.86620399e-01,\n",
              "        1.18345833e+00, -1.40960097e+00, -8.15373585e-02, -3.75827640e-01,\n",
              "        1.55177903e+00, -1.67298496e-01,  2.03314900e+00, -7.43230224e-01,\n",
              "        1.94185138e-01, -9.69374955e-01, -1.17410906e-01,  3.97647589e-01,\n",
              "       -1.18265712e+00,  1.22977436e+00,  5.06062329e-01,  1.20857894e+00,\n",
              "       -2.39146262e-01, -7.08460927e-01,  2.80120909e-01, -7.95280486e-02,\n",
              "       -6.21945143e-01, -2.25386888e-01, -8.98108065e-01,  3.91531527e-01,\n",
              "        9.31277573e-01, -6.49962485e-01,  1.09552729e+00,  6.47159994e-01,\n",
              "        5.88729940e-02, -5.77073812e-01, -3.74660045e-01, -6.66623831e-01,\n",
              "       -5.41471660e-01,  7.45893836e-01, -2.38316625e-01, -8.20898056e-01,\n",
              "        1.15704584e+00,  3.13058436e-01, -4.17980291e-02,  7.85313919e-02,\n",
              "        3.62086117e-01,  6.77459240e-01,  3.94364715e-01, -4.63892013e-01,\n",
              "       -2.32021287e-01, -4.85377461e-01, -1.23948373e-01, -4.73849922e-01,\n",
              "       -7.41982341e-01,  7.23888576e-01, -1.67818427e-01,  5.34410357e-01,\n",
              "        1.31448472e+00, -1.60922396e+00, -5.12732685e-01,  5.34672976e-01,\n",
              "       -1.67538512e+00,  1.36647224e+00,  2.85879616e-02, -8.39485586e-01,\n",
              "        5.85881233e-01,  3.56801480e-01, -1.56651711e+00, -1.01784587e+00,\n",
              "        8.01483616e-02,  1.60043275e+00,  1.05943710e-01,  2.64861107e-01,\n",
              "       -1.70341700e-01, -9.66573536e-01,  1.99415863e-01,  1.84379172e+00,\n",
              "        1.34978962e+00, -5.58784783e-01, -5.09204507e-01,  5.19330919e-01,\n",
              "       -1.29551101e+00, -5.67700267e-01, -2.94523090e-01,  1.02437699e+00,\n",
              "       -5.38879752e-01, -5.74230671e-01,  9.24599707e-01,  5.56473851e-01,\n",
              "        4.36812252e-01, -3.78670663e-01, -8.97205055e-01,  1.93295062e-01,\n",
              "        7.61470199e-01,  5.03422692e-02, -6.36918426e-01, -6.38774097e-01,\n",
              "        4.52661783e-01, -1.51569590e-01, -1.10484552e+00, -3.73878151e-01,\n",
              "       -8.52113068e-02, -7.25390613e-01, -6.30313993e-01, -1.20826352e+00,\n",
              "        1.51835382e+00, -9.28854704e-01, -1.41446173e+00,  7.06618667e-01,\n",
              "        2.17258245e-01, -2.96982020e-01,  6.71858013e-01, -5.86398721e-01,\n",
              "       -5.41873239e-02, -1.92044094e-01, -9.08865511e-01,  1.82160211e+00,\n",
              "       -1.10181940e+00, -5.32917321e-01, -1.03246295e+00,  2.33397007e-01,\n",
              "        1.83470771e-01, -7.58751988e-01,  6.48173869e-01,  4.70781863e-01,\n",
              "       -7.45895281e-02, -1.95480585e+00,  1.01984382e+00, -1.33784590e-02,\n",
              "       -7.23459363e-01,  4.45600569e-01, -2.50336200e-01,  1.33039629e+00,\n",
              "       -2.14191824e-02, -7.71597505e-01, -1.13559318e+00,  5.93119085e-01,\n",
              "        7.57415235e-01,  1.91061354e+00, -1.07736349e+00,  4.03312922e-01,\n",
              "       -2.41000339e-01, -3.76952924e-02, -5.24902940e-01,  3.79807025e-01,\n",
              "       -1.74928296e+00, -5.66732645e-01,  1.34352243e+00,  7.19959259e-01,\n",
              "       -2.26065800e-01,  1.86734033e+00,  2.23599121e-01,  9.44118798e-02,\n",
              "        1.00603557e+00, -9.84436572e-01, -1.02868116e+00, -4.19444263e-01,\n",
              "       -1.25722432e+00, -8.26188207e-01,  1.43718767e+00, -7.98690200e-01,\n",
              "       -8.09668064e-01, -3.23104531e-01,  1.09990442e+00,  8.39753926e-01,\n",
              "       -8.68383706e-01, -6.75036788e-01, -5.35350144e-02,  5.08383475e-03,\n",
              "        1.19396545e-01,  8.14533532e-01, -7.58679286e-02,  3.44682187e-01,\n",
              "        1.24365099e-01,  8.51322651e-01, -2.17483819e-01,  8.89284968e-01,\n",
              "        1.17485392e+00, -1.34797847e+00, -9.55304086e-01, -7.48040378e-01,\n",
              "       -2.99453467e-01, -3.75055820e-01, -5.94838202e-01, -2.89362401e-01,\n",
              "        9.68944013e-01, -1.91399682e+00,  5.34659997e-02, -1.33775961e+00,\n",
              "       -1.23759709e-01,  6.94248617e-01, -5.27361274e-01, -3.41376394e-01,\n",
              "       -6.99196011e-02,  6.77721381e-01,  3.77673119e-01, -2.33366594e-01,\n",
              "       -4.34561431e-01, -3.74525368e-01,  1.19137383e+00,  1.23904634e+00,\n",
              "        4.21502650e-01,  2.15984493e-01,  8.27018678e-01, -3.89387816e-01,\n",
              "        1.18403828e+00,  2.08699092e-01, -2.26807804e-03,  8.37469041e-01,\n",
              "       -3.71354222e-01,  6.96500778e-01,  7.45217800e-01,  2.27371073e+00,\n",
              "        8.10939595e-02,  1.12741196e+00,  2.76942492e-01,  9.55864429e-01,\n",
              "       -1.46141255e+00,  1.18523049e+00, -3.99456114e-01, -1.14675546e+00,\n",
              "        7.99270451e-01, -3.12964231e-01, -9.46885169e-01,  9.14209306e-01,\n",
              "        3.71038169e-01, -4.25016940e-01, -1.84503179e-02, -1.20727670e+00,\n",
              "        2.85664392e+00,  3.98216426e-01, -1.02080750e+00, -1.38179421e+00,\n",
              "       -6.93959057e-01,  2.34945729e-01, -5.31331658e-01, -7.21599385e-02,\n",
              "        1.47204244e+00,  5.11023283e-01,  9.00265455e-01,  1.39562404e+00,\n",
              "       -5.02661347e-01,  3.94589305e-02,  8.66192997e-01, -7.43249476e-01,\n",
              "        5.41565061e-01, -5.40773690e-01,  1.27377880e+00,  3.17029357e-01,\n",
              "       -3.88359249e-01,  2.93730199e-01, -1.05842495e+00,  3.54982466e-02,\n",
              "       -7.98784912e-01,  3.15580696e-01, -9.97388244e-01, -8.06859255e-01,\n",
              "        1.60805619e+00, -5.48383534e-01,  1.69523582e-01, -1.21899271e+00,\n",
              "        3.46009672e-01,  5.39410770e-01, -8.47023606e-01,  9.26154673e-01,\n",
              "        1.23873234e+00,  8.44957352e-01, -1.96602233e-02,  2.51757711e-01,\n",
              "        9.39279497e-02, -5.86934499e-02,  9.18486774e-01,  5.64700484e-01,\n",
              "       -1.90925047e-01,  2.62906462e-01, -4.04414475e-01,  7.06433475e-01,\n",
              "       -4.32721853e-01, -2.32847668e-02, -9.29615080e-01,  8.98845971e-01,\n",
              "        8.41456354e-01,  1.70591801e-01,  4.02422071e-01, -9.03736949e-01,\n",
              "       -1.91217884e-01, -1.31686795e+00,  6.08447529e-02, -6.37157381e-01,\n",
              "       -3.31588626e-01,  7.67677546e-01,  1.03788042e+00,  7.76455581e-01,\n",
              "       -4.88286242e-02, -4.62563895e-02,  5.81230700e-01, -4.63930458e-01,\n",
              "        1.57233584e+00,  5.14465272e-01,  1.06525314e+00,  1.97179270e+00,\n",
              "        4.13651675e-01, -6.85250700e-01, -9.25917745e-01, -1.15567505e+00,\n",
              "       -7.47121349e-02,  6.80945992e-01,  3.38414252e-01, -8.31612289e-01,\n",
              "       -4.73208725e-02, -3.15753996e-01,  5.06944716e-01, -2.84124941e-01,\n",
              "       -9.04755771e-01,  1.19393265e+00,  3.43853652e-01,  2.40344957e-01,\n",
              "       -6.07885063e-01,  2.96138197e-01, -6.47724748e-01, -7.27371275e-01,\n",
              "       -5.74215174e-01,  2.95935690e-01, -3.04833781e-02,  5.16512245e-02,\n",
              "       -1.83233917e+00,  1.88559160e-01, -5.39362207e-02,  1.15828228e+00,\n",
              "        5.00748567e-02, -9.24604654e-01, -5.71336031e-01, -1.34207487e-01],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengubah array embeddings menjadi matriks dua dimensi\n",
        "X = embeddings.reshape(embeddings.shape[0], -1)\n",
        "\n",
        "pca = PCA(n_components=2, random_state=0)\n",
        "X = pca.fit_transform(X)"
      ],
      "metadata": {
        "id": "kcxphdW1QngM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform KMeans clustering\n",
        "num_clusters = 1\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=0, max_iter=1000)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Assign each journal to its cluster\n",
        "cluster_labels = kmeans.labels_"
      ],
      "metadata": {
        "id": "rzaZanE_SOiZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6882bb-d332-42a9-f001-97e9d14dcd66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_vector_distribution(vector_representation, kmeans_labels):\n",
        "    # pca = PCA(n_components=2, random_state=0)\n",
        "    # pca_result = pca.fit_transform(vector_representation)\n",
        "\n",
        "    # df_pca = pd.DataFrame(pca_result, columns=['Dimension 1', 'Dimension 2'])\n",
        "    df_pca = pd.DataFrame(vector_representation, columns=['Dimension 1', 'Dimension 2'])\n",
        "    df_pca['Cluster Label'] = kmeans_labels\n",
        "\n",
        "    cluster_palette = sns.color_palette('tab10', n_colors=len(np.unique(kmeans_labels)))\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(x='Dimension 1', y='Dimension 2', hue='Cluster Label', data=df_pca, palette=cluster_palette)\n",
        "\n",
        "    # Menambahkan centroid ke dalam plot\n",
        "    centroids = []\n",
        "    for label in np.unique(kmeans_labels):\n",
        "        # centroid = np.mean(pca_result[kmeans_labels == label], axis=0)\n",
        "        centroid = np.mean(vector_representation[kmeans_labels == label], axis=0)\n",
        "        centroids.append(centroid)\n",
        "    centroids = np.array(centroids)\n",
        "    plt.scatter(centroids[:, 0], centroids[:, 1], marker='^', c='red', s=50, label='Centroids')\n",
        "\n",
        "    plt.title('PCA Latent Representation with Centroids')\n",
        "    plt.xlabel('Dimension 1')\n",
        "    plt.ylabel('Dimension 2')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_vector_distribution(X, cluster_labels)"
      ],
      "metadata": {
        "id": "-y8vBVgOSYqm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "b3e75021-78fb-4fcb-ae27-30f1d1215fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendapatkan koordinat pusat cluster\n",
        "centroid = kmeans.cluster_centers_\n",
        "\n",
        "# Menghitung jarak antara setiap titik data dengan centroid\n",
        "jarak_ke_centroid = np.sqrt(np.sum((X - centroid)**2, axis=1))\n",
        "\n",
        "# Menentukan batas jarak yang dianggap sebagai \"outscoop\"\n",
        "outscoop_threshold = np.mean(jarak_ke_centroid) + 2 * np.std(jarak_ke_centroid)\n",
        "\n",
        "# Memisahkan data yang masih masuk dalam \"scoop\" dan \"outscoop\"\n",
        "scoop_data = X[jarak_ke_centroid <= outscoop_threshold]\n",
        "outscoop_data = X[jarak_ke_centroid > outscoop_threshold]\n",
        "\n",
        "print(outscoop_threshold)"
      ],
      "metadata": {
        "id": "bL31htlKSlna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "361c212f-c6fd-4397-eb08-38bb82aa9fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113.10079574584961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_vector_distribution(vector_representation, kmeans_labels, scoop_labels, new_data_pca=None):\n",
        "    pca = PCA(n_components=2, random_state=0)\n",
        "    pca_result = pca.fit_transform(vector_representation)\n",
        "\n",
        "    df_pca = pd.DataFrame(pca_result, columns=['Dimension 1', 'Dimension 2'])\n",
        "    df_pca['Scoop Label'] = scoop_labels\n",
        "\n",
        "    cluster_palette = sns.color_palette('tab10', n_colors=len(np.unique(kmeans_labels)))\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(x='Dimension 1', y='Dimension 2', hue='Scoop Label', style='Scoop Label', data=df_pca, palette=cluster_palette, markers=['o', 'X'], legend='full')\n",
        "\n",
        "    # Menambahkan centroid ke dalam plot\n",
        "    centroids = []\n",
        "    for label in np.unique(kmeans_labels):\n",
        "        centroid = np.mean(pca_result[kmeans_labels == label], axis=0)\n",
        "        centroids.append(centroid)\n",
        "    centroids = np.array(centroids)\n",
        "    plt.scatter(centroids[:, 0], centroids[:, 1], marker='^', c='red', s=50, label='Centroids')\n",
        "\n",
        "    # Menampilkan posisi data PCA baru\n",
        "    if new_data_pca is not None:\n",
        "        plt.scatter(new_data_pca[:, 0], new_data_pca[:, 1], marker='s', c='black', s=50, label='New Data PCA')\n",
        "\n",
        "    plt.title('PCA Latent Representation with Centroids')\n",
        "    plt.xlabel('Dimension 1')\n",
        "    plt.ylabel('Dimension 2')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return df_pca\n",
        "\n",
        "# Menentukan label untuk scoop dan outscoop\n",
        "scoop_labels = np.ones(len(X))\n",
        "scoop_labels[jarak_ke_centroid > outscoop_threshold] = -1\n",
        "\n",
        "df_pca = plot_vector_distribution(X, kmeans.labels_, scoop_labels)"
      ],
      "metadata": {
        "id": "0dkFISgYVbMt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "outputId": "b69632e7-fbde-4acf-8a39-3807fca7edec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-f9d194638d11>:10: UserWarning: \n",
            "The palette list has fewer values (1) than needed (2) and will cycle, which may produce an uninterpretable plot.\n",
            "  sns.scatterplot(x='Dimension 1', y='Dimension 2', hue='Scoop Label', style='Scoop Label', data=df_pca, palette=cluster_palette, markers=['o', 'X'], legend='full')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "journal_type = 'finetuning_sinta'\n",
        "\n",
        "# Assuming 'jurnal_id' is a variable containing the directory name\n",
        "file_path = f\"/content/drive/MyDrive/skripsi/src/{journal_type}/{jurnal_id}\"\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "  os.mkdir(file_path)"
      ],
      "metadata": {
        "id": "YIkAdB9TV4hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import joblib\n",
        "\n",
        "# Simpan model KMeans\n",
        "filename_kmeans = f\"{file_path}/{jurnal_id}_kmeans.pkl\"\n",
        "joblib.dump(kmeans, filename_kmeans)\n",
        "print(\"Model KMeans telah disimpan dengan nama:\", filename_kmeans)\n",
        "\n",
        "# Simpan threshold\n",
        "np.save(f\"{file_path}/{jurnal_id}_threshold.npy\", outscoop_threshold)\n",
        "print(\"Threshold telah disimpan.\")\n",
        "\n",
        "# Simpan data sebaran PCA\n",
        "np.save(f\"{file_path}/{jurnal_id}_pca_data.npy\", X)\n",
        "print(\"Data sebaran PCA telah disimpan.\")\n",
        "\n",
        "# Simpan data sebaran multibert\n",
        "np.save(f\"{file_path}/{jurnal_id}_bert_data.npy\", embeddings.reshape(embeddings.shape[0], -1))\n",
        "print(\"Data sebaran PCA telah disimpan.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFaa2yonCWPA",
        "outputId": "e35aaa6f-cdee-4260-f73b-8f859d8963b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model KMeans telah disimpan dengan nama: /content/drive/MyDrive/skripsi/src/finetuning_sinta/1/1_kmeans.pkl\n",
            "Threshold telah disimpan.\n",
            "Data sebaran PCA telah disimpan.\n",
            "Data sebaran PCA telah disimpan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Membuat DataFrame dengan data teks dan label scoop\n",
        "df_res = pd.DataFrame({'Data': data,\n",
        "                   'Label': scoop_labels})\n",
        "\n",
        "# Memisahkan data dalam scoop dan outscoop\n",
        "inScoop_df = df_res[df_res['Label'] == 1]\n",
        "outScoop_df = df_res[df_res['Label'] == -1]\n",
        "\n",
        "df_res.to_csv(f'{file_path}/{jurnal_id}_data_jurnal.csv')\n",
        "inScoop_df.to_csv(f'{file_path}/{jurnal_id}_inscoop_data_jurnal.csv')\n",
        "outScoop_df.to_csv(f'{file_path}/{jurnal_id}_outscoop_data_jurnal.csv')\n",
        "\n",
        "print(\"Data dalam scoop:\")\n",
        "print(inScoop_df)\n",
        "\n",
        "print(\"\\nData outscoop:\")\n",
        "print(outScoop_df)"
      ],
      "metadata": {
        "id": "p6bN0n1GV9jb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a972a1bc-154e-4f6c-ba6a-015964e9e262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data dalam scoop:\n",
            "                                                   Data  Label\n",
            "0     kemampuan bahasa inggris awal pada periode lin...    1.0\n",
            "1     strengthening early childhood learning outcome...    1.0\n",
            "2     eksplorasi deskriptif tentang layanan bimbinga...    1.0\n",
            "3     perspektif orang tua terhadap pelaksanaan les ...    1.0\n",
            "4     strategi pencegahan dan penanganan stunting mu...    1.0\n",
            "...                                                 ...    ...\n",
            "1463  pembelajaran kosa kata bahasa inggris dengan m...    1.0\n",
            "1464  pencapaian perkembangan anak usia dini di tama...    1.0\n",
            "1465  colour ball based on microcontroller as a educ...    1.0\n",
            "1466  pengembangan teknologi digital cerita sains te...    1.0\n",
            "1467  pengaruh bimtek guru pembimbing khusus terhada...    1.0\n",
            "\n",
            "[1392 rows x 2 columns]\n",
            "\n",
            "Data outscoop:\n",
            "                                                   Data  Label\n",
            "21    pengembangan profil pembelajar knowledgeable d...   -1.0\n",
            "39    problematika manajemen kurikulum merdeka pada ...   -1.0\n",
            "53    belajar bilangan dengan konteks memasak kue bo...   -1.0\n",
            "63    desain pembelajaran steam dengan media selasi ...   -1.0\n",
            "77    virtual realitybased instructional media throu...   -1.0\n",
            "...                                                 ...    ...\n",
            "1387  metode collective painting untuk meningkatkan ...   -1.0\n",
            "1405   and keyword of the article temporary the cont...   -1.0\n",
            "1428  tumbuh berkarakter membangun kecintaan pada ni...   -1.0\n",
            "1459  validation of digital learning media to improv...   -1.0\n",
            "1468  managing english young learners classroom acti...   -1.0\n",
            "\n",
            "[77 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Predict**"
      ],
      "metadata": {
        "id": "fnoZdRB-0oYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "def fit_new_data_to_pca(new_data, pca):\n",
        "    # Transformasi data baru ke ruang PCA yang sama dengan data lama\n",
        "    new_data_pca = pca.transform(new_data.reshape(1, -1))\n",
        "\n",
        "    return new_data_pca"
      ],
      "metadata": {
        "id": "GhgIyIuGC74F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_scoop(text_data, tokenizer, model, kmeans_model, scoop_threshold, pca_data):\n",
        "    # Preprocess title and abstract\n",
        "    processed_text = preprocess_text(text_data)\n",
        "\n",
        "    # Tokenize new data\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "        processed_text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=128,\n",
        "        pad_to_max_length=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Calculate embedding for new data\n",
        "    input_ids = encoded_dict['input_ids'].to(device)\n",
        "    attention_mask = encoded_dict['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        new_embedding = outputs.cpu().numpy().reshape(1, -1)\n",
        "\n",
        "    new_data_pca = fit_new_data_to_pca(new_embedding, pca)\n",
        "    print(\"new data :\", new_data_pca, \"cluster center :\", kmeans_model.cluster_centers_)\n",
        "\n",
        "    # Calculate distance to centroid\n",
        "    distance_to_centroid = np.sqrt(np.sum((new_data_pca - kmeans_model.cluster_centers_)**2, axis=1))\n",
        "    print(\"Distance\", distance_to_centroid, \"threshold :\", scoop_threshold)\n",
        "    print(\"inscoop\", distance_to_centroid <= scoop_threshold)\n",
        "\n",
        "    # Determine if new data is in scoop or outscoop\n",
        "    if distance_to_centroid <= scoop_threshold:\n",
        "        prediction = \"in scoop\"\n",
        "    else:\n",
        "        prediction = \"out scoop\"\n",
        "\n",
        "    return prediction, new_data_pca"
      ],
      "metadata": {
        "id": "uL8hLI-JDJ6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "judul_baru = 'PAE AMDFWIE SKDFJWEI LADFK WLA DKFA IWEF MADSFLL EW IALFAS DKFEIW ALFAS'\n",
        "abstrak_baru ='dsalfkejlk aslkdf ael akdf alie dlf ajefo wa jdkafl kwpa jdfj alie ajdlfk ajweil pq lsfj alwe alfj jkeaji dlf kea lt [a fpds pof  af kas l iq lkdsa jifel akt li il af laifelakai alf kalei altk alif wlak t m, aal it lakfldiafaelka df aieal'\n",
        "\n",
        "text_data = judul_baru + abstrak_baru\n",
        "\n",
        "# text_data = \"halo test ini bukan bagian dari cluster\"\n",
        "\n",
        "# Predict scoop for new data\n",
        "scoop_prediction, new_embedding = predict_scoop(text_data, tokenizer, model, kmeans, outscoop_threshold, X)\n",
        "print(\"Prediksi scoop untuk data baru:\", scoop_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgElyrTxDNsF",
        "outputId": "913436f7-835d-4886-91c8-f35814b5258c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[144.21164  63.03061]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [157.38441] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "Prediksi scoop untuk data baru: out scoop\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan label untuk scoop dan outscoop\n",
        "scoop_labels = np.ones(len(X))\n",
        "scoop_labels[jarak_ke_centroid > outscoop_threshold] = -1\n",
        "\n",
        "df_pca = plot_vector_distribution(X, kmeans.labels_, scoop_labels, new_embedding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "WXkoz2DlDPlL",
        "outputId": "1be7769c-6355-40b5-e83c-935657bfe259"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-f9d194638d11>:10: UserWarning: \n",
            "The palette list has fewer values (1) than needed (2) and will cycle, which may produce an uninterpretable plot.\n",
            "  sns.scatterplot(x='Dimension 1', y='Dimension 2', hue='Scoop Label', style='Scoop Label', data=df_pca, palette=cluster_palette, markers=['o', 'X'], legend='full')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Baca data gabungan\n",
        "df = pd.read_csv(f'{file_path}/{jurnal_id}_data_jurnal.csv')\n",
        "\n",
        "# Pisahkan fitur dan label\n",
        "X = df['Data']\n",
        "y_true = df['Label'] # Label sebenarnya\n",
        "\n",
        "# Prediksi menggunakan model yang sudah ada (asumsikan fungsi predict_scoop sudah didefinisikan)\n",
        "y_pred = []\n",
        "for text in X:\n",
        "    prediction, _ = predict_scoop(text, tokenizer, model, kmeans, outscoop_threshold, X)\n",
        "    y_pred.append(1 if prediction == \"in scoop\" else -1)\n",
        "\n",
        "# Hitung metrik evaluasi\n",
        "precision = precision_score(y_true, y_pred, pos_label=1)\n",
        "recall = recall_score(y_true, y_pred, pos_label=1)\n",
        "f1 = f1_score(y_true, y_pred, pos_label=1)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhcI-3B_EDH6",
        "outputId": "39021cdb-3b20-47ae-a145-cebf5da7ec79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.534288     0.37714595]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.537445] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -2.0484543 -22.790787 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.88266] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.6439886  8.460424 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [8.86394] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.956152  10.986959]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.9875] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[38.32221    1.4024538]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [38.347862] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.675343    2.1477225]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.776827] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-8.890112  8.474077]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.281858] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 9.45122  13.758504]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.691973] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[100.89723  -19.057652]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [102.68128] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 12.610669 -13.840492]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.724] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.064125    0.5799057]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.071745] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.318804  -0.763509]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.332472] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.727608   1.144637]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.762556] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.145594   -2.3703213]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.291765] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-17.505398   4.629712]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.10727] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.945467    0.9846946]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.966585] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.44393     3.7362537]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.91934] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -2.4803305 -23.329075 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.460558] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.333272 -26.90036 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.247139] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[13.2669735  5.297229 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.285419] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.356586    1.2130495]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.39101] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[178.98218  92.77728]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [201.59921] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[19.518536   -0.91187525]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.539825] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.518814    -0.09190004]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.51901] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.176552    6.7301435]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.795821] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-16.637327    6.2086973]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.758057] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.1700340e+01  1.5954345e-02]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.700346] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 54.4159   -60.729603]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [81.54247] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.0860287e+01  1.0691673e-02]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.860289] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.641619    1.8570571]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.717648] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-1.0764726  6.719713 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [6.8053894] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.4573555 -25.499718 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.733032] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.039894    -0.30652577]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.042128] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.533936     0.93800145]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.554356] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.77999      0.54668236]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.786549] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 6.405469 15.70192 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.958193] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 5.8278747 14.058216 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.218328] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.093449    2.8308237]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.291876] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.483475    2.8429418]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.726841] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[146.37535 136.82874]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [200.36928] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[  1.8232411 -29.164642 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [29.221577] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -4.5942774 -20.347393 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.859621] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 15.399127 -40.552925]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [43.378254] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[17.81443   -4.1685553]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.295649] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 0.6946228 11.442237 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.463301] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-7.065485 11.095968]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.154527] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.639774  10.394226]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.148859] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-13.610539   6.802772]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.215928] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[70.06679 59.1969 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [91.72583] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  8.954999 -35.44478 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [36.558506] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.820374   -0.1892097]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.821323] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.579369   -0.6304254]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.588167] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-12.410125    6.9044847]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.201518] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[141.32257 165.24875]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [217.43785] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[  0.19987178 -31.701344  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [31.701973] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.5557692 -22.452105 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.505941] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.245983    0.7427394]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.257845] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.955162     0.68368626]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.964916] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.578873    2.0191486]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.665169] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.875206   1.121237]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.903921] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 64.72729  -19.781729]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [67.68263] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.42794      0.15294063]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.428513] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.885971    1.6719943]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.956137] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[179.55879   62.517754]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [190.13109] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[ 10.593614 -30.360737]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [32.155857] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.750317    2.6048603]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.913177] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.178373   2.180645]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.290342] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.618151    5.3043017]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.614706] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.175602   -1.1103323]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.204693] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.877434     0.14439568]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.877958] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.634777    1.0291666]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.658163] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-4.6417227  8.348143 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.551809] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[46.164646  1.180645]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [46.17974] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.6274633 -25.382887 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.640778] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.146008   2.976995]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.37607] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.33688     5.1958447]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.193106] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.8782      4.2369657]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.401882] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[181.45    -96.71675]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [205.61671] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[  0.12739724 -29.162458  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [29.162737] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.510124   9.037008]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.43278] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[-19.91083     3.5301957]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.221361] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[19.157757  9.386221]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.33356] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.186276 -26.792744]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.290083] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 6.2122955 18.3476   ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.370779] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.306089   6.881865]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.98039] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.80423     2.1220498]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.917595] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.688103    2.7249517]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.858618] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.682262    1.3388643]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.725552] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[-13.4734745   4.792363 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.300393] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-25.99782      0.50926274]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.002808] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.757101    2.5182886]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.925396] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.526463    -0.13197935]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.52685] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.2148436e+01  1.7377436e-03]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.148436] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[105.57172   91.951996]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [140.002] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-22.996695    2.2920065]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.11063] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  1.0529511 -26.914963 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.93555] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[24.703175  5.088517]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.221813] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-19.626717     0.53402776]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.63398] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-7.387308 12.443359]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.470988] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.348455   1.188327]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.384912] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.74247     1.8940125]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.824808] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[21.811615  7.646019]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.112944] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-8.83039    3.5098999]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.5023775] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.301964    0.7510108]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.31585] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.924      -0.3471518]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.92652] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -7.778117 -23.569935]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.820171] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.086979    0.7788338]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.101357] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.035984    2.1168888]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.14223] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.1052138 -22.994314 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.020859] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.482964    1.6795337]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.548517] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 1.6784561 11.967362 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.084493] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -8.475611 -16.986975]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.984028] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.591812    -0.32683745]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.594286] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.772242    -0.11679301]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.772554] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.174463   -0.4080002]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.178053] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 26.481964 -45.779167]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [52.886925] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.152958    2.4892392]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.31404] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 8.852049  -5.6740475]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.514447] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.39579      0.13759467]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.396233] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 8.011353 14.81466 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.842087] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-8.353636   7.5604916]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.266954] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.475643    2.1508117]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.583076] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.720934   -1.1180146]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.747265] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.738659   9.41216 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.279619] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 53.31854 -62.92247]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [82.47487] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -7.193405 -22.550312]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.669847] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.615526    -0.96789116]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.638235] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.128487     0.86149436]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.14525] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.772182    1.0369021]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.799353] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-0.5160041 17.196152 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.203892] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.59296     1.6059834]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.647558] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.457981    1.1906989]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.48818] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.034998    1.1000345]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.063742] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.010775    -0.47446552]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.015665] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.12437     2.1969726]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.243937] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.163357    1.9519141]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.249144] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 34.609245 -14.780056]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [37.633095] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.093075    1.7911263]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.162432] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.659903    -0.47330427]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.665073] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.029009    1.9958608]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.12351] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  1.4187684 -25.365013 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.404661] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[46.54547  -4.016961]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [46.718487] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.103672    -0.54139835]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.110615] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.01213     1.4044334]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.056889] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-7.011195 10.944475]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.997629] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.27721     -0.06828788]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.277325] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.76753    -0.5443175]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.774662] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.067816    1.0062242]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.090744] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.208385    1.9178405]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.28749] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.357979    1.2707796]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.39252] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.268986    5.4642816]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.217283] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[34.947945 34.00681 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [48.762917] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.336018    1.5515158]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.392355] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.157534   2.892099]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.363949] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-0.88324934 10.99638   ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.031794] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 5.7858257 -6.170264 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [8.458602] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.394052   3.466818]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.779596] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.971596   7.127859]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.581768] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.67976     -0.06611732]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.679852] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.900784   0.616003]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.909859] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.05402     2.0716853]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.160744] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  0.6606426 -24.275024 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.284012] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.641235   4.762266]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.272722] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.954056     0.28210294]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.95579] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.660854   2.494415]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.818459] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.70745     0.6361184]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.717218] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.332905   2.757963]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.510445] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.148256    -0.40981033]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.152641] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[13.81824  11.227305]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.804384] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.849594    0.7414682]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.862171] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[39.989532 43.312447]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [58.95024] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.484208    4.0847116]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.049157] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.83047     2.6923513]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.995867] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.363953     0.27354717]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.365625]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -6.189823 -24.45058 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.22191] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.556871   6.278226]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.038915] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -6.1697063 -23.463295 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.260902] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.71835     1.2699008]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.755444] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.7934     1.509694]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.845627] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.081287   1.806376]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.158537] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.247993    2.5873604]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.43051] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.446148    2.0580273]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.549463] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.8580016 -28.48555  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.546082] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.670013    1.1157439]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.696295] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.397156    2.2881951]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.519157] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.399079   9.035037]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.775803] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.708696    1.7244824]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.780375] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.524298    1.7153332]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.589518] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.475687    1.5918846]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.54414] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[111.426636 123.47974 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [166.3224] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-19.379354   2.345116]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.520731] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.71471     1.2142285]]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.750267] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-25.182648    1.3190979]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.217173] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.038193    -0.29091004]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.04003] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.073658    -0.08633512]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.073826] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[34.429707 13.817493]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [37.098892] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.14257     1.2552149]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.17812] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  0.1993261 -27.527084 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.527805] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  4.060349 -31.817768]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [32.075798] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.51429      0.60616255]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.523243] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.100201   7.811629]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.001106] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.25436      0.19474937]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.255253] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 1.9634197 11.855106 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.016594] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[13.382565 -5.634129]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.520208] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[59.06496    0.8575473]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [59.071186] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.221516    1.4238769]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.283888] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.85035     1.2191415]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.88285] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.343468    2.0891309]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.436764] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.978134     0.53461206]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.984352] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[157.43536 125.37941]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [201.26076] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-17.896513    1.5265663]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.961504] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.41657      0.23675765]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.41788] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-7.4812164  9.043821 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.73709] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.17041     1.6071334]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.228584] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.860004    3.2367914]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.109632] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.562283    1.3762375]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.60244] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.719517    4.8313804]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.36637] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-3.193143  9.638636]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.1537895] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.850494     0.36695737]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.853724] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.398674    0.8677329]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.415476] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 1.0057635 13.502661 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.540066] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.0089042  8.873562 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.09812] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[130.18346  83.86932]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [154.86057] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-15.847072    5.4875436]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.770294] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.100887   2.588122]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.284979] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.726383    4.9598455]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.446259] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-17.579918    2.5454013]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.763237] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 14.8570385 -31.669815 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [34.98155] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[20.93301  26.260122]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [33.582508] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.553236    0.1900084]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.553972] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-11.4993515  10.341936 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.465792] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.32436    6.142338]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.58575] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.30183      0.79253936]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.316568] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.044632   9.43256 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.757086] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.544304    -0.32460618]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.54664] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.29192     0.9478965]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.31301] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[101.06203   22.208078]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [103.47334] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.48167     2.4337492]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.61302] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.196967   6.002537]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.339468] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-19.061434    3.4609768]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.37309] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 6.5772166 20.016869 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.06976] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.2039957 -24.12983  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.341616] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[24.686577  -8.2567425]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.030767] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-0.85493934 14.384462  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.409846] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.719788   -1.9506063]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.857758] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.698723  16.92339 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.021584] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[210.7872 -99.4796]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [233.08246] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-15.07118     5.6057177]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.079943] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-0.468178 14.98015 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.987464] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.931004   1.822417]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.003307] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.067726    1.2815299]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.108603] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-0.8341143 -8.242264 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [8.284364] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.13723      0.83920443]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.162116] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.598625    5.7831774]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.702388] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[  3.250241 -29.43536 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [29.614262] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -6.02524  -25.635826]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.334372] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 8.0524981e-03 -3.0399925e+01]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [30.399927] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  1.5162218 -25.214062 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.25961] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.067757  -0.116182]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.068048] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.264286    2.2293549]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.38083] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.854832   -0.8214271]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.870264] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -6.5967216 -24.79108  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.65374] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.077843    1.2846859]] cluster center :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.116957] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.308052     0.10593775]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.308304] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.511112    1.1484412]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.541746] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[56.98819  23.715977]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [61.726017] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.394709    0.8036629]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.408508] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.421116     0.85954547]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.437586] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.715953 -25.584171]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.015188] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[54.91993  19.545696]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [58.294365] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.927578     0.28359947]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.929333] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.838713     0.27089173]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.840393] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.74203     1.4005454]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.78709] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.238735   -0.8062219]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.254032] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.629189    1.7314372]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.69838] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 16.735207 -16.706966]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.647194] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.8956575 -22.239037 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.77152] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  1.2746992 -33.313038 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [33.337418] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.200432   9.397844]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.600365] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.071716    1.8773849]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.147974] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[10.036688   6.0331154]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.710404] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.130455    0.5959234]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.13813] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[106.375626 -40.950283]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [113.98552] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-19.859686    2.5803785]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.026619] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.43433     1.5335846]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.484457] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.7846546 -26.445303 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.07058] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.355074    1.7238406]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.424538] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 1.9026797 11.83313  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.985121] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.622185    0.7346213]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.635931] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.867306    0.6769192]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.87778] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.010355     0.32897967]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.01293] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[143.4928  102.78096]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [176.50526] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-14.301223   4.083637]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.872829] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.473526    3.2522306]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.730225] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[134.77713  -89.568726]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [161.82532] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-23.01191      0.19137356]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.012705] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 8.430435 10.890903]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.772581] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -0.34404868 -26.955078  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.957273] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[124.20647 151.0077 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [195.5264] threshold : 113.10079574584961\n",
            "inscoop [False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -7.212591 -28.214746]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [29.122044] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 1.2703618 12.234526 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.300302] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.39724     0.7474433]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.41029] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.2891445 -23.597736 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.183222] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[123.61174  -92.903885]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [154.6318] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-3.1899717  9.945944 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.444984] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.021152   1.792042]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.087906] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.079674    5.8022695]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.09451] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -0.98407716 -27.295822  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.313555] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[162.93921 -95.8961 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [189.06415] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-15.318338   8.564053]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.549772] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.19524     1.3643731]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.239107] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.592793   0.874244]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.608984] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-10.31665   16.387772]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.364717] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -2.721045 -24.16227 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.315002] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 32.299423 -52.0961  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [61.296463] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.911833    1.0530815]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.937124] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.882809    1.2457645]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.916695] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.402237    2.4296093]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.546392] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.558678    1.3719883]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.604406] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.93636     1.4065309]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.977648] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.521917    1.5618197]] cluster center : "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.581263] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[60.99153 71.35825]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [93.87208] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.482597     0.90034187]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.500618] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.1756315  -4.0874677]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.843418] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.040114     0.34819305]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.04615] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[153.34021  -29.836964]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [156.21608] threshold : 113.10079574584961\n",
            "inscoop [False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-19.628906   4.378726]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.111368] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.960337     0.13604638]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.96074] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.22957     1.8888478]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.313433] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 28.753527 -39.378403]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [48.758835] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.394547    0.9030613]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.41453] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-1.4420754  4.357437 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [4.5898614] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.340733     0.39749372]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.344816] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.583794    2.0119662]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.673239] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[ -1.9341778 -28.610943 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.676247] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.385052   -0.3073387]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.38726] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.959076    1.9182149]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.042698] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-8.884731 -8.156271]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.060814] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.425632    0.7933054]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.43851] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.815844   1.79064 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.886002] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 5.107752 16.288616]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.070683] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.731031    3.4951167]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.168877] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.087296    2.8398802]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.269115] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.490578     0.79556954]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.505299] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[22.39719    4.6876264]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.882483] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.017555    0.8728924]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.035673] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.68938     2.2497003]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.81749] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.875117    4.3151884]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.530647] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.789106     0.37212208]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20.792437] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.30091     3.0239148]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.549053] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.250126   -0.8558774]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.268204] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -6.2315006 -23.360565 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.17742] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.975407    1.4338987]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.022139] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.967655    1.6538005]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.027119] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.25628     1.3684208]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.29831] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.52592     2.0584266]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.628876] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.800266    1.4806145]] cluster center : [[-4.1548780e-08  7.7384607e-07]]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distance [21.850489] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.824255   4.864129]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.513288] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.185326    1.6713908]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.254404] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.012548    3.8358972]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.41646] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.120505    4.2395573]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.788455] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 16.709139 -25.807247]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [30.744257] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-15.987349    4.6672287]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.654678] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.758408    1.6520584]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.827354] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.908154    -0.81799084]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.923418] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.237549  -1.496449]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.287842] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.605743  17.506948]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.46888] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.967255     0.21182644]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.968275] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.445152     0.31855878]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.447634] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[159.95258 142.04468]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [213.91942] threshold : 113.10079574584961\n",
            "inscoop [False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-5.008161  8.860832]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.178212] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.1995616 -27.502945 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.68843] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.677631    0.4973898]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.683916] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-11.558956   9.213888]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.781921] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.524853    1.3008885]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.570473] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 2.453702 12.533397]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.771322] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.501467    1.4440756]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.552263] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.54766    2.429124]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22.678131] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.289707    1.3584481]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.333002] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-0.36336458 10.1971    ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.20357] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.499011    4.7497864]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.257188] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[-22.218513    3.5929456]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.507145] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[35.97473   5.494445]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [36.3919] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.22382     0.7684927]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.237103] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.19199      0.88675016]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.208937] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.07454     1.9206634]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.157938] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-19.619343    2.4598417]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.772947] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.202955    5.0537996]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.020947] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[82.637184 48.258667]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [95.69641] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.2001     7.769327]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.873417] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.65178     -0.02877989]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.651798] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -6.9865294 -26.32264  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.23404] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[157.49359 163.21655]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [226.81242] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-22.430626     0.48523128]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.435873] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.927288    0.7382865]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.940308] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.363523     0.89677286]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.384277] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -6.54707  -22.026276]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.978706] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.858234    2.8645356]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.045135] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-8.995739   1.1894264]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.074032] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.702772    4.9529767]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.46539] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.96259     1.6492615]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.027369] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.648233   -0.1625416]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.648817] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-9.664442  5.134109]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.943515] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.58633     -0.30847025]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.588348] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-1.4413126 12.955902 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.035826] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[33.119694   0.9360118]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [33.132915] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.872467   4.650538]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.501648] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.76773     2.0386348]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.872574] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[51.08158  85.542145]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [99.633255] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.208008  10.845356]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.329641] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.164936     0.47269082]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.170765] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-2.9883766  8.552166 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.059245] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[32.790062  4.127374]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [33.0488] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.089139    6.7002425]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.601188] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.386463   1.115947]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.424417] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[75.21452  -8.899173]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [75.73916] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.070585 -23.216267]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.306358] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.663427     0.10412648]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.663666] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.880191 -24.530613]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.225536] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.38446     1.1305497]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.411774] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-2.9625175 13.359228 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.683766] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.646156   8.955584]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.911977] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.053053    4.6477804]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.712341] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[78.33271  49.913963]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [92.883896] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[156.25165 163.19139]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [225.93364] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[ -4.99814  -23.847239]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.365389] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.478231    2.0036447]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.57602] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.785957   2.295027]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.912273] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 49.14663  -12.961883]]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [50.827175] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.7472      1.2847712]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.78895] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.879646    1.7581732]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.9471] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.885857    1.4962424]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.939383] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.988123    2.1360466]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.091633] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  3.066165 -30.826584]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [30.978697] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 81.42749  -14.807325]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [82.76287] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.683804    5.7216873]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.586409] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.354801    2.4133208]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.504679] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 37.61418  -29.086859]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [47.54863] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 181.95052 -102.09335]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [208.63614] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-22.002789    1.3205606]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.042381] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.796076    1.5980788]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.857388] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.7756171 -23.218367 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.286163] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-17.51569     4.5104456]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.087109] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.160164   -0.6074169]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.168127] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-9.769251 11.399181]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.012648] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.230892    1.5554106]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.287792] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-11.671816  -2.19347 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.876136] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[47.163063 16.134909]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [49.84666] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.850212   5.969136]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.772736] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[195.75655  74.33527]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [209.39522] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[6.010914  7.1214337]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.319114] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.665045   -1.1392328]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.69978] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 2.8993347 12.449827 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.782969] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.870167     0.53996456]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.877151] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[16.078417 14.992355]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.98377] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.909489    2.6740675]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.079786] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.714912    0.7364136]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.727999] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.14594     1.1671846]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.176678] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-3.7270963 11.101387 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.710339] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[20.40945  12.298876]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.828722] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 35.763275 -56.585785]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [66.939995] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.10726     3.6029143]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.386457] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.14095     1.2091174]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.172516] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.2725365 -26.177095 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.38086] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.769947    1.0393698]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.794744] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.82242  -25.952648]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.396887] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.91836     1.0656211]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.943121] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.414959    2.6752362]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.589499] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.37595     0.9300655]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.394445] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -9.126282 -24.788647]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.41526] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.311892    1.7984401]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.387638] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.77032    1.045844]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.795427] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  0.42530012 -28.775175  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.778318] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.63872     0.8378396]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.654217] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.419888   4.216485]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.922924] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[-23.168129     0.51116663]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.173767] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.968204     0.51609206]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.974266] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.709406   -2.3810868]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.860313] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-15.622725   5.849371]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.681866] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.852154    1.0441716]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.879595] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.84318     0.6645004]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.853285] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-19.955936    1.2704397]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.996336] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.451015    2.6428883]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.629745] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.5913744 -23.34391  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.791153] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.507786   5.481924]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.851795] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.917935   5.670179]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.89768] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 193.98685 -104.85054]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [220.50972] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[22.627542  8.49806 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.170698] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  1.8741918 -27.778942 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.842094] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.7079086 -2.346274 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [3.582984] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-11.849022   9.466896]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.166457] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 206.96419  -106.666016]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [232.8343] threshold : 113.10079574584961\n",
            "inscoop [False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.207638    1.6692955]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.273233] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.094677    2.1149664]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.200436] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.36615     6.7254333]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.62296] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.151695    1.4750416]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.20075] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-5.0674295 11.941777 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.9724655] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[19.010307   4.7144194]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.586157] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[165.43521 -68.31743]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [178.98625] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-20.666012     0.33415735]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.668713] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.453453    2.0415504]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.56604] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[26.285107 21.239449]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [33.7938] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  5.845205 -31.210583]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [31.75322] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.44274     1.0275985]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.46525] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.673439   2.60222 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.836569] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 2.1960196 11.311685 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.522877] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  6.0255704 -31.942902 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [32.506252] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.247673    1.5263956]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.299974] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.524748     0.87053245]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.541563] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.98582      0.42721206]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.989624] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.560429   8.179732]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.372059] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.346252     0.41932023]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.35037] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-13.809226   2.618712]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.055332] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.465824   2.213718]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.585201] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.850151    2.8818908]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.127203] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.9148493 -24.240381 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.315893] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.367756    2.4485369]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.514404] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.395346   3.004257]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.668322] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[151.251   151.96933]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [214.40976] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[37.92269   9.740067]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [39.153538] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[-14.5637245   2.0912936]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.713109] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 205.59698  -109.380905]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [232.8826] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-21.853033    2.4157457]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.986153] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-8.273603  -2.3701732]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [8.606407] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.54253     2.6870716]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.717525] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.079527   -1.1466494]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.110691] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.651089    0.5704225]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.658966] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.67612     1.5660534]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.730135] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.027447   9.403755]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.06689] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.128843     0.93780065]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.150677] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.967873    3.7953255]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.364338] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.329101    9.6505165]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.656921] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.367485    2.6018357]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.52531] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.821018    1.3285925]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.85966] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.621292   4.939407]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.433079] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.359165    -0.34312844]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.361921] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[84.59121  42.285458]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [94.57131] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.878653    4.3979053]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.476442] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 5.2530146 12.056371 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.151053] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.660576    2.7135458]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.83801] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.491854    5.6483874]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.489445] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 8.168762  13.9825325]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.193823] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.550585     0.04523589]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.550634] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[2.4135275 7.289448 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [7.6786165] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.624227   5.753084]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.649757] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 22.584158 -49.57669 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [54.478367] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 8.432373 15.615646]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.746923] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.716549    0.5198679]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.722496] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.549126    -0.14351979]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.549562] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[19.510664  -1.5762358]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.574232] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.150576    1.9616022]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.241344] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.221774  10.564112]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.923822] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.786915    1.2358094]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.817703] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.970282    2.5104187]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.12745] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.2634193e+01  2.1769822e-02]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.634205] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 2.2140245 10.051737 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.292682] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.646996    2.0595603]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.749464] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.734995     0.06593639]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.7351] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.2022705   2.3527606]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.427022] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[132.96451  41.39061]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [139.25783] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-23.740694     0.22120342]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.741724] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.702177    0.8569629]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.718346] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.01575     2.5324717]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.148907] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 14.976334 -18.645723]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.91555] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.076622     0.78354204]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.09052] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.998207    2.5008423]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.139904] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.96067     1.2918534]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.000443] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.302078    -0.29633597]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.304047] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.846413     0.70881677]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.857407] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 8.50273  12.348831]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.993] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-11.662584    3.9676142]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.319003] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-9.469452  4.273424]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.389065] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[164.28549   47.584633]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [171.03807] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-21.369928    -0.41431805]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.373943] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[37.487144 11.201287]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [39.124863] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.393501   4.301921]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.889875] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.748543   7.990656]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.659761] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 17.876308 -34.946815]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [39.253563] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 2.6182504 15.566954 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.785603] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.041046     0.18477607]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.04182] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.409658    1.9017919]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.502605] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[20.711182  8.72139 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.472553] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  8.809238 -38.635822]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [39.627384] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.440125    1.6551503]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.501081] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.784782   2.19204 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.894789] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.920525    0.6553358]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.929892] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.8056982 -12.168343 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.749585] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.9449      2.5870907]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.141256] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.430002     0.63387316]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.438957] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.643856   0.587042]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.6522] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[79.86041 80.84703]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [113.639465] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-15.788537   5.541871]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.732908] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.5877      3.4846601]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.867136] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[32.653923 -4.646821]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [32.9829] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.20985     1.9358066]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.298006] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 209.39807 -104.11163]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [233.85205] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-22.814655     0.65146303]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.823954] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.734253    0.5802237]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.741997] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[-20.248       1.8563056]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.332912] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.996494     0.82789695]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.014526] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.850685    1.8006873]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.936493] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.672197    2.5694542]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.823982] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  0.6812588 -28.797329 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.805386] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.664957    7.3776555]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.416174] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.7089    -1.548674]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.761646] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.822495   -0.5377533]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.828829] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.386986   1.754644]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.458843] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  1.925317 -27.310913]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.378693] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.604053    -0.08496034]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.604221] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 10.237555 -35.27528 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [36.730816] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.138313    0.3057264]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.140524] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.9132      0.2611072]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.914688] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.295528    1.2033257]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.3295] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[23.044054 25.70208 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [34.519928] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 14.492774 -46.315796]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [48.530334] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 19.500828 -10.55957 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.176268] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.445276   1.256953]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.483877] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.021038   0.921289]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.040302] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-9.990843 13.520105]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.811014] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.56261     5.1208467]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.256] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.073536     0.23568468]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.074795] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[141.18683 162.36256]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [215.16347] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-18.637068    1.9220868]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.73592] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.883574    -0.09460846]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.883799] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 3.4692473 13.293673 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.7389] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.087326     0.95493424]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.107067] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.047363     0.48985642]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.052351] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.800985    3.4716744]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.15592] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 15.343169 -41.49514 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [44.240925] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.538685    1.1877519]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.573] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.868034   2.364523]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.995497] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.846365    2.9864843]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.06981] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.785903    5.4470034]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.822988] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.662899    2.7791872]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.840446] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[68.56298  46.189453]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [82.67011] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.675824   6.401313]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.200468] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.07793    2.329504]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.212616] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.822056     0.64022624]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.831036] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 36.475056 -48.39315 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [60.599724] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.323338    0.2776213]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.324991] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.623777     0.26391536]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.625317] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  3.4164019 -17.959446 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.281507] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.32093     -0.07820201]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.32106] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.61723      0.34741348]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.620655] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.159578    1.8864938]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.247654] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -2.4502506 -27.5587   ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.667412] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.390682     0.40123358]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.394445] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.151543    0.9895917]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.174679] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.179657    -0.09833241]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.179886] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.21633    -0.8567141]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.23362] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-1.340925  9.270197]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.366675] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 6.240594 16.177048]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.339027] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.030188    1.0425406]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.052792] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.404694     0.03792128]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.404724] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.1870901e+01 -4.5013428e-03]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.870901] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-0.2033951 17.23244  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.233643] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.0116344e+01 -9.2184842e-03]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.116346] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.273094    0.8150307]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.288702] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.278984   -0.2446196]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.280458] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[44.37436 38.0167 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [58.43247] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.033554    -0.03131846]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.033577] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.031948    3.6232123]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.341755] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.673098    3.4829047]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.080796] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.032993   2.473914]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.171446] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[149.20673  -13.301274]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [149.79843] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-21.840015    0.7984557]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.854607] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -6.6273727 -23.250463 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.176561] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-9.321344 13.537106]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.435957] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.522417   -1.0118302]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.546188] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.762253     0.95021415]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.782988] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.54451  -26.680557]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.250572] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.263533    2.1962492]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.382204] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.0602      1.0534413]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.08425] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  3.293939 -13.569744]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.963811] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[40.857327 11.67572 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [42.492867] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.941658    1.5807376]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.996052] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.184021     0.52531487]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.190239] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-5.2193103  7.8729687]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.445889] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.500626    1.0216258]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.522821] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.861233  10.342602]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.105955] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.3472217 -25.294052 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.329905] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.6084      2.6605678]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.808268] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-1.4960895 14.818243 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.893575] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.282265    -0.84415615]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.29825] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[39.34791  -8.555688]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [40.26733] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[12.308238  3.836466]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.892292] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.040543    0.7644192]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.053795] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.329733    2.9619365]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.544369] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.55652      0.02952614]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.55654] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.228622    1.8726819]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.311062] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.725697    0.5783099]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.733053] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[26.371632 15.227396]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [30.452202] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[10.741776   6.7043295]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.662298] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 12.188837 -37.64926 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [39.573154] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-14.181995   -0.6362454]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.19626] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.49702  -23.848917]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.474232] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.234371    1.2725544]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.270758] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.680836    1.3220716]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.721107] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[17.698282 15.528962]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.545229] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 25.822222 -12.880123]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.856276] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[130.70444    0.575118]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [130.7057] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[ 49.6495   -65.497345]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [82.18866] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.105324     0.34537727]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.107798] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.698326     0.55354804]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.70479] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-12.736826    5.9623117]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.063281] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.416368    -0.88438827]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.43462] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.005857   0.971416]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.027287] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.94534     4.9761314]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.660872] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 4.364058 14.095757]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.755857] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.979372   1.41573 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.02492] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-7.0109873  2.100366 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [7.318844] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.149498    -0.24874896]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.151114] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.079916    2.3276205]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.214373] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-17.428593    1.0726488]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.461569] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.0485084 -22.54031  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.564684] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[166.31046 -94.86852]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [191.46593] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-20.702164   1.800777]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.780336] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  8.958863 -23.098726]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.775238] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.422129   6.895046]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.985601] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.818708    2.2589486]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.002127] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.16126    0.840693]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.176514] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.641972    -0.34553123]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.64473] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-4.9940634  6.503166 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [8.199502] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.11333     5.0241947]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.8356] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.959219    1.2819071]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.994978] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.785141 -23.845848]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.537569] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[98.97693 50.40535]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [111.07264] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.396713    4.6902456]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.054342] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.884247    1.7046154]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.950535] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.692638    0.5449701]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.699814] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[34.699867 -6.061721]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [35.22535] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 204.24213 -101.78166]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [228.19806] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-22.438       2.5418386]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.581514] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.604112    5.2520113]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.519784] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.112561   4.360776]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.72914] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.927307    2.6692185]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.089172] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 17.611685 -44.800232]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [48.137638] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[145.27649 164.83694]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [219.71909] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-21.916746   1.116913]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.945187] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.734013   -0.1208528]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.734333] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-16.121761    5.7325773]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.110628] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[167.85988 148.46414]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [224.09494] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[  1.6930768 -31.90967  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [31.954556] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.21772     3.2994657]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.498903] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.710014   1.708104]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.780334] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.507536   5.842931]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.022818] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.476519    0.8589837]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.492228] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-6.881523  7.820803]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.417308] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.4921      -0.57028615]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.499664] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.228603   3.090171]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.452337] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.836159   5.518248]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.717428] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.633474    2.3821614]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.764235] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.273914    0.5695415]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.280884] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.173601    -0.21959634]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.174858] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.215084    0.4643256]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.220165] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.333682    5.3301487]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.292643] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[16.135838 30.367516]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [34.388245] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.527287    3.6699095]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.86915] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 88.22023  -12.893452]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [89.15745] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.409086    2.2656164]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.555891] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-3.7354238  2.5084064]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [4.499499] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.480425    1.8687435]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.56156] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[97.04935  52.326332]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [110.257065] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.4159355   1.1271099]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.457084] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[18.739435  -1.9777288]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.84351] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  5.2859945 -33.203407 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [33.62154] threshold : 113.10079574584961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inscoop [ True]\n",
            "new data : [[ -5.6789103 -24.363094 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.016203] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.999989   -1.0223576]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.0227] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 59.81987  -11.224453]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [60.863823] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 11.466037 -31.863455]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [33.863693] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[10.61833  16.534124]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.650093] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.3085074 -26.016811 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.552866] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.413171 -22.269382]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.702456] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.806309    2.1271324]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.91476] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.840885    -0.18042356]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.841599] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[138.53102 -98.9297 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [170.22905] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[ -3.173411 -22.945953]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.164354] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.257961    -0.10157022]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.258204] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.804363    0.6263774]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.812963] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -2.7696264 -30.681591 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [30.806345] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[64.53532  60.741844]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [88.62493] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-2.9754672  9.610767 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.060826] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[90.53526  66.308395]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [112.22049] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.319475   0.781536]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.332567] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[40.79654 36.78016]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [54.92848] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.382172    -0.16125625]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.38292] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 1.3590825 10.448639 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.536657] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.237034    2.2211175]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.358559] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.553852    1.7100903]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.621586] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[83.63414 64.01225]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [105.319695] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.329678    1.4989444]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.377783] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 2.7118554 10.477567 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.8228245] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.267962    1.5586748]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.322447] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.93359     2.1651583]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.040197] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.3489857e+01 -1.9197792e-02]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.489864] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[211.1124   -99.186035]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [233.2516] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[ -3.0566883 -24.097004 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.290098] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[29.96949  39.207603]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [49.34984] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[41.157433 12.102827]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [42.900032] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.314102    2.8396995]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.511621] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.324848    2.0001986]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.41845] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.020685    6.7700562]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.31768] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.870266   8.737561]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.9466] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 6.7089834 11.861936 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.627764] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.98998     1.8977885]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.064928] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.4875317 -24.733715 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.137514] threshold : 113.10079574584961\n",
            "inscoop"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [ True]\n",
            "new data : [[-23.624132     0.04528385]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.624176] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-5.2547474  6.3489842]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [8.241478] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.80893    1.155719]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.857208] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-5.782321  9.326239]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.973329] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.73491     2.3484557]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.86748] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.312557    1.0213466]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.33492] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.993782    1.1852795]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.024311] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.166739   2.945916]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.361635] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  0.23772591 -28.63322   ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.634207] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.456837   0.820361]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.477272] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.928577     0.76922655]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.941477] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.778477    1.7570337]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.84924] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.899567   5.586073]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.798864] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.986683    1.0001479]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.011692] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[141.64305 156.43327]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [211.0311] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[48.461334  8.513669]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [49.20349] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.82032      0.39542383]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.824076] threshold : 113.10079574584961"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "inscoop [ True]\n",
            "new data : [[-23.55537      0.34454095]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.55789] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 20.013   -47.44658]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [51.494644] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.448466   9.705805]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.260893] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.89589     1.5070722]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.950167] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.329924    3.0854557]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.562729] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.7574      1.8830806]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.846937] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.31718      0.18110497]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.317915] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.957722    2.2895212]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.088617] threshold : "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.865395    -0.25777203]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.866787] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.620766    1.2705011]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.658062] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.538492    3.7054763]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.003276] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.2594233 -22.550339 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.949083] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-6.576745 10.614057]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.486463] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  2.892621 -33.71537 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [33.83923] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-1.202198 10.922082]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.988045] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-16.981499   8.842318]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.1457] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  3.6363754 -38.704292 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [38.87474] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 202.1973  -110.14111]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [230.24945] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-17.45353    3.402893]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.782166] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  3.7852092 -34.36466  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [34.572495] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.0006824 -23.621714 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.145231] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.426197    1.5542843]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.479994] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.252102    2.5772154]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.423838] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.92309     1.5779833]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.977339] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-0.57608   -2.9274492]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [2.9835937] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.015451    1.1038347]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.043106] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[77.16406  -9.801119]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [77.78403] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.1207920e+01  6.1142445e-03]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.20792] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 196.64905 -110.20669]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [225.42484] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-18.544472    3.5504966]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.881298] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.481426     0.47080448]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.486147] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 51.36017  -12.408852]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [52.83793] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-15.275591    6.2612567]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.508997] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.828442    0.9353357]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.84847] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.033684    5.6455975]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.944893] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[96.29578  23.696842]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [99.16863] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -0.7291812 -28.624142 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.633427] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.899187   4.595824]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.51297] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.20414     1.1411788]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.233446] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[120.97772    -4.8545184]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [121.07508] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-20.263298    0.7382409]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.276743] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -6.9613824 -25.596394 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.526142] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.4664593 -24.595358 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.195513] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  1.1036878 -27.5752   ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.597279] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.861832     0.83192587]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.878414] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 8.444149  -2.2195113]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [8.730972] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.540771    -0.09126964]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.540956] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 194.18208  -105.135086]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [220.81682] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[ -4.4731607 -25.581522 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.969664] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[13.402091 12.816298]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.543827] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.513533     0.95750463]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.53483] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.27644     1.3714528]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.318617] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[13.655284 20.803524]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.884804] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[101.500626 -82.28215 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [130.66266] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[22.86652   -6.1789265]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.68664] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.6136923 -23.291708 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.958656] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[30.32351 42.42566]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [52.14836] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[88.75168 70.61713]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [113.417984] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-22.402187     0.26628074]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.40377] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.889752   9.01228 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.727902] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.39732     1.4058307]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.441397] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  1.7953969 -19.160524 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.244457] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.035175    1.2430942]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.073704] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.340557    1.6665598]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.40553] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.303936    1.5822332]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.362612] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.563343    3.2647123]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.820889] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-13.18531     5.9397964]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.461452] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.861286     0.99172807]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.88377] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-14.449705   2.454774]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.656735] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.192446     0.54297197]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.1994] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.154957    3.1247225]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.395739] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 49.953003 -64.395874]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [81.49927] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.328837    6.4408956]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.80348] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.496582   1.299625]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.532495] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.893242    1.0207361]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.915987] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -3.0931072 -21.757158 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.975924] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.034626    1.2202759]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.071754] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.340893    1.6560223]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.402185] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-1.9044958 10.980669 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.144603] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.698235     0.79101336]] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.712013] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.149874    5.2911506]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.905401] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -9.388071 -26.95708 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.545053] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.996479    1.4956748]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.04727] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[2.1789873 6.4847884]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [6.841086] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.394052   3.466818]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.779596] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-11.527943    7.7769575]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.905916] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.879517   2.357572]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.000662] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-4.530463  8.528986]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.657571] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.722774 -12.034591]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.512863] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[80.45631 74.10077]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [109.380714] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-12.74819     4.6072936]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.555202] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-8.992104  6.764518]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.252404] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.40627     5.6416607]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.406752] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.10539      0.38017803]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.108519] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.727749   2.242118]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.843126] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 0.5768341 15.718933 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.729512] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.250185    3.4731154]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.532137] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.474548    1.9463649]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.558672] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 195.25356 -106.48996]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [222.40518] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[82.89006  45.526497]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [94.56968] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-17.07945     4.3148026]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.616049] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.18896    -0.7946991]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.203857] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.456444    -0.27768567]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.458328] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-2.4103806 13.670603 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.881474] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.586567    4.4244733]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.105927] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.7878222 -24.719017 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.783585] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.947376    1.5045522]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.998886] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.2856817 -26.071083 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.420984] threshold :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[22.855108 29.965254]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [37.6865] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.634953     0.38100332]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.638308] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[50.232227 -5.556728]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [50.538635] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.453773   -0.5858462]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.461414] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.6795      1.8926661]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.755018] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.537994    2.8870156]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.750141] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.4385679 -25.848694 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.0764] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.027584    1.4264232]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.069887] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.530804    1.1863295]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.56069] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.275904 -15.041567]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.415113] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-3.3367105 10.805141 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.308612] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  5.3000984 -27.905895 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.404755] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.56301     1.0577484]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.588938] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 203.04057 -105.6364 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [228.87665] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-18.802464   -0.9200988]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.824963] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.686333    1.0298831]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.709698] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.800068   5.950173]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.768244] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.97485     2.0760283]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.08808] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[33.722847 30.722092]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [45.618828] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.12408     1.6542715]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.188755] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.515991    4.1030083]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.125038] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.56108      0.21577275]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.56216] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.968195   4.42453 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.569843] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.230255    2.0499449]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.320528] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.494999    0.8028178]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.50932] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.422668   -0.3982372]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.426205] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  8.024883 -29.514524]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [30.58604] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 203.18048 -107.97891]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [230.09074] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-21.486492     0.98904073]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.509243] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.47507     1.0855057]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.50127] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[74.68154  25.639864]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [78.96034] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-6.711771   6.5428214]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.373173] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[14.480597 24.961323]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.8575] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 0.4013133 13.132437 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.138567] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.817669   8.117238]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.67414] threshold :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 28.99647  -56.015907]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [63.075962] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  4.2783337 -29.21986  ]]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [29.531414] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.088923     0.28740233]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.09071] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[66.495384 22.62733 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [70.23982] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -3.55932  -20.598406]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.903662] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-1.1864696 15.34613  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.391927] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[154.10059 164.802  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [225.6251] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-2.3654152e+01 -2.2104383e-03]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.654152] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[65.31825 50.55726]]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [82.59849] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.91083     3.5301957]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.221361] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -2.978696 -28.28754 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.443937] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[136.13936  17.83131]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [137.30215] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[  3.5027924 -27.478899 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.701254] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.053045    0.6468961]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.062983] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[146.9092    15.684185]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [147.74406] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-21.251705    -0.40038466]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.255476] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.491615    1.4564868]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.543312] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.229969    0.9867459]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.251858] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -3.0233784 -27.689617 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.854187] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.502548   -1.0375069]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.526453] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 19.211143 -19.884254]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.648718] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.06644      0.11180383]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.066738] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.256918  -0.941201]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.275955] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.4981      3.1903753]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.733541] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.013523    1.9636123]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.100927] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  1.4787757 -27.197573 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.237743] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[72.07533  31.558575]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [78.68162] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 202.63782 -105.50728]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [228.45978] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-2.0887812e+01  1.7939895e-02]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.88782] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[80.19287  38.906166]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [89.13241] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.697028 -23.782232]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.24163] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.762646     0.95988804]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.785944] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 25.434177 -34.001823]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [42.462] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[62.67873 -1.66244]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [62.70077] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.5502381 -26.699894 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.934895] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.173466    1.8419604]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.253435] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.040226    2.1700048]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.146795] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.032661    2.3609753]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.164759] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.588453    -0.20520663]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.589386] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.056663 -24.958439]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.144917] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.280584     0.06638372]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.280687] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.409388    1.7881336]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.477583] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  0.39775318 -22.823656  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.827122] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.743416    1.5771115]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.800537] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.312275    2.2268505]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.423124] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.539167    1.9156516]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.624186] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.072926    0.7035134]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.084665] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.552507   1.920556]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.646605] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.972937    0.9467561]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.991625] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -8.707021 -13.736021]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.263165] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.071415    1.2683016]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.107826] threshold : 113.10079574584961\n",
            "inscoop [ True]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "new data : [[16.612099 31.936508]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [35.998642] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 10.976526 -31.152225]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [33.02946] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  2.0578227 -27.914185 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.989933] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.55096    6.019616]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.919854] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -9.220425 -11.857777]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.020756] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -0.5565748 -27.149385 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.155088] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  4.8640776 -36.500656 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [36.823322] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.345634   3.13654 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.61183] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.878242    -0.39541247]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.88166] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.912678     0.28699598]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.914646] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.804787    1.5991632]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.866156] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.510079   6.552356]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.122161] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.489143  -1.496264]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.549587] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-14.140384   4.599082]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.869499] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-1.2547681 13.809223 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.866113] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[24.161057  7.048744]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.168262] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.862408    5.1547284]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.730937] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[1.7449474 9.192003 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.356161] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.16224     2.2206886]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.284164] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-4.798972  5.414628]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [7.2352138] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[58.053204 22.8149  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [62.37543] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-2.2123487  9.84539  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.090896] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 1.4467937 11.990866 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.077833] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-6.826234 14.479023]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.007484] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-1.0182841 10.29415  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.344391] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.6490178 -21.968616 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.269608] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 6.5866528 21.903316 ]]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.872238] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.578595    3.7662015]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.02738] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.974962    1.3341496]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.019468] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.09114     0.9501624]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.112532] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.450619    3.7041821]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.783377] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -7.4169817 -24.33316  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.438442] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[67.50488  11.981889]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [68.560005] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.634254   -0.3761947]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.637524] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.428585   -1.4293288]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.474083] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 9.309149 19.22966 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.364458] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 0.37571922 11.7007065 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.706736] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[69.394806  -2.2925775]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [69.43266] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.152748   2.816672]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.39649] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-0.8251798  7.771709 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [7.815393] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.667812    0.5314396]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.67404] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.96896     1.1066426]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.99814] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-11.065518    1.1952585]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.129885] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  1.9600966 -28.92772  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.99405] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 2.7167988 13.418688 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.690951] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.463707    2.0580945]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.56694] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -6.268475 -24.315914]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.110903] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.289562    4.7412605]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.863705] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[91.66407  29.390518]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [96.260605] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.34504      0.73585236]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.357153] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[153.95474 166.06058]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [226.44685] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-20.297836   1.322243]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.340858] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.352327    -0.56798506]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.359234] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.423971    1.3569659]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.469] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[0.6949502 7.9901843]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [8.020348] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.213139    5.8737297]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.136852] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.420845     0.93407786]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.442198] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.678356    1.2861857]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.716478] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-1.9291006  9.13802  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.339422] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.297785    7.1738224]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.89633] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 64.550095 -64.96245 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [91.57966] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-11.483004  -9.065297]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.630072] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-18.34317     2.6400244]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.532179] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.526634     0.08673665]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.526802] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.926029   7.429386]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.7838545] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.110477    1.5009035]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.157148] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.169456    1.6227455]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.23463] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.282167   9.416796]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.1072] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.99976    2.117898]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.097065] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  1.4302685 -27.260666 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.29816] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.549654   1.99894 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.63808] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-15.957916   4.363041]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.543615] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.620094    -0.11372298]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.620358] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.550398    -0.38853112]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.553745] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.992435   1.9668  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.080206] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[68.88031 36.62031]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [78.0099] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.505413    2.4706724]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.64687] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.085226    1.5366619]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.141148] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.478308    -0.09086367]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.47849] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[139.79843 -45.32023]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [146.96097] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-14.735655   6.107795]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.951322] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 202.6962  -107.15074]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [229.27501] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-21.804562    1.4403214]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.852081] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.840418    1.2202829]] cluster center : [[-4.1548780e-08  7.7384607e-07]]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distance [21.874481] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.6311026 -25.9869   ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.590002] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.532446   1.300887]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.568375] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.223839    6.6040983]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.171318] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[53.615273 10.770991]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [54.686485] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.938671     0.81175995]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.953684] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.427883   3.022685]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.66162] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[212.0326  -98.55136]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [233.81657] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-21.281513   -2.0128279]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.37649] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.742851    1.2094474]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.77808] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.342327   8.665031]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.497417] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[51.61267  29.367975]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [59.38304] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.7992538 -27.159452 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.218985] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.617216   5.092266]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.538217] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.608257    -0.05231416]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.60832] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[33.192577  9.712553]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [34.5844] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.409166    1.4810132]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.460331] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-17.448683    3.1509905]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.730913] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 21.330662 -43.483036]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [48.433167] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.200733   6.251478]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.192799] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.90006    4.098423]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.339321] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -0.72924405 -32.472313  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [32.4805] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.975306    1.1634077]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.007545] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[3.564376 9.479913]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.127858] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.828354    0.9326038]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.850273] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.927906    6.9374466]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.22337] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 2.8434045 -6.1216035]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [6.74974] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.656067    -0.31706175]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.6585] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.359741    1.5876813]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.416039] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.423512    2.3113708]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.553886] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[-21.419495   -0.2711446]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.421211] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  5.8632846 -27.77642  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.388514] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[79.565445 69.35863 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [105.55226] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[14.930637 10.41223 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.202703] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.473411   3.79464 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.962584] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.920486    2.6927485]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.093071] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.80967     1.3874679]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.853758] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 60.200573 -11.963495]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [61.3778] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.126488    2.5239997]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.301369] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -2.723264 -26.847569]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.98533] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.202555   -0.1953036]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.203499] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  4.7840095 -29.799751 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [30.181316] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.878471    3.0634623]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.091906] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 190.37994 -108.04538]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [218.90256] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-16.083717    3.5724263]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.475685] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 38.70797  -13.130355]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [40.87436] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.1362      3.2939157]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.403833] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.599148   1.543294]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.651781] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.801495    1.2120092]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.835157] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.247269   4.447033]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.781343] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[117.33322  -30.908892]] cluster center : "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [121.33608] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[ -1.7529093 -23.453495 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.51891] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[34.626724  -7.8156424]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [35.497807] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 5.528985 13.494419]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.583175] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.94043     2.5400577]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.093922] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.670677    2.1610482]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.783335] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.216602    -0.67978597]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.226551] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-1.97506   9.938591]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.132938] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 7.880122 17.894398]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.55264] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[213.79453 -24.36509]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [215.17842] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[ -3.6923206 -28.820034 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [29.055595] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-12.2631645   7.6868844]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.473195] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.760418    1.3003445]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.799236] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 89.94914  -33.205864]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [95.88262] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.527367   6.803842]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.041716] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-13.046923   6.127242]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [14.414065] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[46.18599  15.802202]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [48.814495] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.984737   -3.4759586]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.382608] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 2.1731803 13.048609 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.228336] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 1.1531342 12.892438 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.943904] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.697348    1.4642453]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.74453] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.294874  10.509155]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.742203] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[11.531561 12.675665]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.1362] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.076435     0.42748228]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.080574] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 0.6837489 16.028234 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.04281] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[46.66514  20.315811]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [50.89565] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.44582    4.061773]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.912415] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.121439    -0.09975335]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.121655] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-11.585016  13.531659]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.813433] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.247131    4.8362045]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.912354] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.8775297 -24.53723  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.608957] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[41.33532 35.70485]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [54.62092] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.17345     1.1485151]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.204576] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-10.277077    7.8183975]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.913003] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.239304     0.30162486]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.24155] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.147358    2.1891534]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.286535] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.836376    2.7831857]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.998312] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.750256    3.3682587]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.998245] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.395866    0.9567438]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.417246] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-18.145996   5.194153]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.874756] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[163.90141 130.44005]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [209.47144] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-23.35611     -0.06661251]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.356205] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -7.0458755 -26.973488 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.878548] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[120.12757  -92.687164]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [151.72852] threshold : 113.10079574584961\n",
            "inscoop [False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-0.48795784 11.561354  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.571645] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.24873     7.2936683]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.006994] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 6.19312  21.405542]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.283445] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.006557     0.36048526]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.00951] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.786882    -0.14379375]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.787336] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.55304     1.2797927]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.594877] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[111.57367   59.292717]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [126.349945] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-15.484137  10.832482]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.89712] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[73.791626  -2.1816437]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [73.82387] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.913889    3.0245347]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.198755] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.44636    2.010298]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.540373] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  8.127203 -18.239105]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.967884] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.821959    2.0040312]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.913786] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.63274     4.4837213]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.226486] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-2.8872008 11.621947 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.975206] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.864544    -0.15015268]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.865036] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[45.58023    1.9006683]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [45.619843] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[2.630888 8.507072]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [8.904596] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.776478     0.28880352]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.778309] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.027874    1.5548197]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.080303] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.393517   3.434918]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.655424] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.786907    1.6684197]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.847906] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-5.0464544 10.045958 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.242239] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  1.4089285 -12.030012 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.112238] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.87888     1.7467153]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.948494] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.522316     0.39555296]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.52579] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 46.407585 -60.82882 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [76.51019] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[12.973305 18.70943 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.767288] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.280113     0.35274413]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.282906] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-19.959179   3.046052]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.190277] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.61622     1.3585923]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.65699] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.14392   1.80505]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.220829] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[14.164601 23.432074]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.380613] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-0.09402025  9.970504  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.970946] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.472862   6.46381 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.630129] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.305416    2.0499973]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.403814] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.634178  -2.111206]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.760107] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-24.153265     0.79406154]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.166315] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.277237    -0.52705765]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.283472] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-17.252256   3.809526]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.667847] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.051035   8.147664]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.000559] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.283268    2.2830024]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.405363] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.185797     0.64814866]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.194855] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.820702   4.594946]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.437016] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.103872     0.86484116]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.123438] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.706541    0.9648082]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.72703] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.574375    0.6226125]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.583357] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.300266    1.0125654]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.323242] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[119.63617   33.668015]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [124.28334] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[-20.872307    2.4213662]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.012287] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.1246433 -25.24929  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.764095] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 209.12186 -101.96263]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [232.65495] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[ -7.303622 -27.215832]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.178793] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.24031     1.1318258]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.26672] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[161.98578 142.34192]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [215.64001] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-21.503773    1.5852721]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.562126] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.876617     0.37884277]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.879753] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-18.76585     2.7097433]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.960482] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-11.713617  10.936775]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.025663] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[31.703247  -4.4146943]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [32.009148] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.027134    1.6154726]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.086294] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.781887    3.9165642]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.208101] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.529928 -23.198624]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.465647] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[ -4.9649415 -24.874374 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.365038] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.388857   1.787665]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.467077] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 58.556965 -68.85329 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [90.38635] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.255049   -0.3915856]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.258493] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[121.47852   24.513794]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [123.92722] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-22.585274    1.0273618]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.60863] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-12.708762  10.856102]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.714293] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.91025      0.92494893]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.928913] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.06919    -0.3293537]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.071646] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.86261     1.1353772]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.893482] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.201546    1.0511202]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.227587] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -5.09223  -25.908068]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.403765] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -4.0280704 -27.914074 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.203207] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.798122     0.19477808]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.79892] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.4385252 -20.92374  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.204395] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.044456    1.9122838]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.127243] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.469528    -0.37097937]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.473063] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.57907    1.279422]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.616964] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-19.196434    4.9411764]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.822166] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.271744   1.425371]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.321793] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.40831    2.989523]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.626108] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-17.836151   8.736502]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.860886] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.830933     0.67671096]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.841923] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.553928    0.8050831]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.569689] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-4.4194484 10.032198 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [10.962504] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[27.04904  17.359497]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [32.140358] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.092014     0.10303655]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.092245] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.574104    1.8826742]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.656096] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 20.036398 -45.996674]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [50.17122] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-18.97243     5.4361672]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.73588] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -0.9238785 -25.639523 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.656162] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-5.3702593 10.667559 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.943051] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-13.751195    1.0959206]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.794796] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[63.12448  20.645298]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [66.414825] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-8.033516   4.9249077]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.4229555] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-12.008896    6.7404327]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.771238] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-25.02383    1.158951]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.050653] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.810635    0.8518337]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.826536] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.42308      0.48505288]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.428326] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 9.039824 22.132225]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.90719] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[22.362835 32.735313]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [39.644634] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 9.944006 19.263447]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.678644] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.688305    1.8079166]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.760221] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.617762    2.6433716]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.778774] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[69.59624 -7.88721]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [70.04173] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.907503   4.821087]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.512472] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.444479   1.574084]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.502172] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  3.6619132 -27.255733 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.50063] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[9.731035 8.752886]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.088393] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[136.48233 -91.72243]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [164.43974] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-22.825298    2.6474943]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.978327] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.003637    -0.25199768]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.005081] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.710442    1.4217045]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.75694] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.065952   2.263255]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.181717] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-0.45472643 12.081226  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.08978] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.880306    0.5914352]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.887949] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ 71.917    -31.508104]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [78.51634] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.766544   2.125504]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.870075] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.2943      1.5485448]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.345715] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.503822    2.3823037]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.635382] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.408876     0.35663077]] cluster center :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.411594] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  0.4755141 -22.652397 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.657389] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.31533     0.5829923]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.322945] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[78.63898  83.054855]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [114.37743] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-8.807369  10.6248665]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.800634] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.807571   3.62938 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.107523] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  3.806363 -30.187057]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [30.426088] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-16.884571    7.4975195]] cluster center : "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.474348] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.63655     1.6322682]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.698032] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  9.437866 -33.711456]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [35.007652] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-18.63419     3.1213374]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.893803] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.354956    1.6883307]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.42159] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-2.1694002e+01 -1.0862112e-02]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.694004] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.994598    1.2066407]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.02492] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.34504    4.047385]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.725378] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.235937    1.8081336]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.30933] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.685163    0.8652097]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.70325] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.919409     0.17598356]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.920084] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.488678    1.4298009]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.541058] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 18.52156  -42.970993]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [46.792675] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-16.924263    4.0821533]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [17.409613] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.012554    1.7433288]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.08148] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.291927   -1.3919712]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.335344] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.495275    1.7297934]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.561684] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -5.0337276 -27.882473 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.33321] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.886301    1.5481848]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.94099] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.885517    1.2079496]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.92217] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.6231093 -23.328613 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.608284] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[-12.593302  13.762632]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.654793] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.302345    2.7764485]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.474503] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -2.0290365 -24.785362 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.868277] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-4.202879 11.3435  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.097073] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.980497    1.0080245]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.0036] threshold : 113.10079574584961\n",
            "inscoop [ True]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "new data : [[-20.055466    2.6310167]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.227306] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-3.8320568 15.14233  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.619693] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.416477    -0.11980969]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.416798] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data :"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [[132.91171 158.05214]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [206.50908] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-20.27091     1.7891213]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.34971] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-4.3448415 17.831612 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [18.353312] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.389004    1.9619143]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.483177] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-16.245708   4.445285]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.842909] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.66063     2.9386406]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.84242] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.267845    0.0427413]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.267885] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.791664    1.6439568]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.853586] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -2.0040605 -23.595236 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.680191] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.163138 -25.213469]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.411108] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  3.6938288 -32.533333 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [32.74236] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.62975     0.7378403]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.641775] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.995659   2.724346]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.171673] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-11.311861    3.3769438]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.805165] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[192.19266 113.05254]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [222.97736] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-22.474907     0.73478055]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.486914] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.626585    1.2547773]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.66135] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.047562    1.1978502]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.077375] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.277214    3.9851813]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.684834] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.43797     2.6132793]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.589636] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.11108     -0.36234182]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.11392] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.6339927 -24.679295 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.733328] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-16.701456    2.2991478]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.858965] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 41.98783 -44.37154]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [61.088554] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.7120376 -26.041016 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.463896] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.92141     1.1409134]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.951078] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -2.3688722 -22.756332 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.879297] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.5216      3.2959838]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.772524] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.127068    1.2442107]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.160511] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 5.3400764 21.39999  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.0562] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.98811     0.8735693]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.005455] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.861572    1.2222961]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.89735] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.353636    -0.97262794]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.375774] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.63062     1.0569417]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.654243] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[111.022446  98.48624 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [148.40999] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-22.177101    1.1951014]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.209278] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.756767    0.9094501]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.782991] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.10903     0.5695671]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.116713] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[57.93834 45.10781]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [73.42728] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.455496   8.811356]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.083853] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.278717   0.237103]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.279924] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.3728133 -28.002361 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.035994] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 26.501137 -38.56137 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [46.789845] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-10.831661   8.547202]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.797809] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.671894   6.273199]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.880796] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.78912    2.625452]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.954248] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.10733    1.298305]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.143776] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-14.861684    2.5024743]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [15.0709] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.5859284 -23.583475 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.854542] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  5.896851 -26.686956]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.330688] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.437239    0.5956296]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.445143] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[  0.96436954 -32.54506   ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [32.559345] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[142.72903  -69.725105]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [158.84952] threshold : 113.10079574584961\n",
            "inscoop [False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.526985   0.92177 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.545835] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-5.7794013  9.677616 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.271988] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.868673   1.857551]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.947422] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.055988    2.9667478]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.263966] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.935562    2.1033428]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.036173] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-15.268885   5.003915]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.067917] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[18.629772 15.752585]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.396975] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.427187    0.7643826]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.441484] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.313435   1.259063]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.35059] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.856335    3.3839965]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.116753] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.370207    1.2011485]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.403936] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.037094    1.6737964]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.100569] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-24.046623    2.3775487]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [24.163874] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.037868     0.25189906]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.039377] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.481926    1.4566374]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.531256] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -4.6909494 -25.301743 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.73292] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.843683    0.8800637]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distance [23.85992] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.946987    1.3145522]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.98304] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-19.345306    2.2893758]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.4803] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -3.8618736 -29.088947 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [29.344181] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -2.0903072 -29.163815 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [29.23863] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.234253     0.18462902]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.234985] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[153.2005   91.72582]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [178.56097] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "new data : [[-23.030312   -0.4534983]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.034777] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-23.643003     0.65558803]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.652092] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.598446    0.7322087]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.610306] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -3.132444 -26.925062]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.106663] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -7.47808  -25.322071]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.4032] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  3.1898706 -34.165215 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [34.313805] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.7906      -0.32429776]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.793013] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-13.150673    2.7759829]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [13.440472] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-14.966377  12.67936 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [19.615265] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.0279219 -26.641018 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [26.660841] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-11.712231  11.432863]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.367245] threshold : 113.10079574584961\n",
            "inscoop"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " [ True]\n",
            "new data : [[ -2.7967453 -25.668262 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.820175] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.555132    -0.19396648]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.555965] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[  0.39216453 -25.093842  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.096905] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-23.644884    1.2893236]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [23.680012] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-16.301746   -2.9644883]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [16.569103] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.329905    2.3185616]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.455547] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[12.443522 24.777695]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [27.726799] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-22.056736    1.7338417]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.124779] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.73391     1.4697208]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.781368] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-22.220798    2.4802353]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.35879] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.886314    4.9827824]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.472452] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -2.7633903 -22.795666 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.962551] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.908422    0.7803724]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.922981] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-20.989578    1.1968954]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.023676] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[2.8849099 8.92627  ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [9.380883] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[1.0618567e-03 1.1131944e+01]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [11.131943] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[1.5345286 8.580161 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [8.716302] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.505865    0.8822615]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.523954] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-20.752348    2.7940893]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [20.939602] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ 207.28293 -109.34507]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [234.35562] threshold : 113.10079574584961\n",
            "inscoop [False]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[ -3.9576287 -25.415754 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [25.722042] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.160233    0.8192544]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.176086] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.952108    1.8851782]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.032906] threshold : 113.10079574584961\n",
            "inscoop [ True]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new data : [[-21.055267     0.83263314]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.071724] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.866592     0.88617474]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [21.884542] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[ -1.6054049 -28.155205 ]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [28.200937] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[-21.917961    2.9520717]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [22.115871] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[12.265502   1.8894714]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [12.410183] threshold : 113.10079574584961\n",
            "inscoop [ True]\n",
            "new data : [[177.62866 -99.44171]] cluster center : [[-4.1548780e-08  7.7384607e-07]]\n",
            "Distance [203.56963] threshold : 113.10079574584961\n",
            "inscoop [False]\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1-score: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2760: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1hoL-3v560zkM672EijVlHiTeC-R1e9nw",
      "authorship_tag": "ABX9TyNvvc0AezSH0un66ZQSDi9n"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "549e78a4233249c2be4925ab10972785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_146f85b994664ee6ade54ecd69a228ad",
              "IPY_MODEL_193f59f390a64230bb77c0275684193c",
              "IPY_MODEL_680bee3994844275a0c08bc555a46311"
            ],
            "layout": "IPY_MODEL_54baf27df5f043fb9fed7804a29c1130"
          }
        },
        "146f85b994664ee6ade54ecd69a228ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31a5e116a8fb4345897b4d7da863878f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cbc800352b3448199f33632c59295968",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "193f59f390a64230bb77c0275684193c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9026ac7bf2f4783ac9764ddafda705f",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f201f191345a41a0bcf41315e939e301",
            "value": 25
          }
        },
        "680bee3994844275a0c08bc555a46311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3efc8966f0ac4c9383874dc8695a4203",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7a441301e03f428483391af53b0776b5",
            "value": "â€‡25.0/25.0â€‡[00:00&lt;00:00,â€‡1.19kB/s]"
          }
        },
        "54baf27df5f043fb9fed7804a29c1130": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31a5e116a8fb4345897b4d7da863878f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbc800352b3448199f33632c59295968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9026ac7bf2f4783ac9764ddafda705f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f201f191345a41a0bcf41315e939e301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3efc8966f0ac4c9383874dc8695a4203": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a441301e03f428483391af53b0776b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89d801d709fd43338b40d37915bc25a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_546978400ae74f769ffa6938c9519330",
              "IPY_MODEL_031f94d744af4c0f9ea6c24080e16449",
              "IPY_MODEL_2e1525a0f7ca41d9a74be54d9bc1a9c5"
            ],
            "layout": "IPY_MODEL_8aa790f4c7274754bc1f8ad69bedc869"
          }
        },
        "546978400ae74f769ffa6938c9519330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_547ccf5eb23840b48cb34a5ff1c1c12c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c3b5ca83609e499285d2c7a02b8e811b",
            "value": "vocab.json:â€‡100%"
          }
        },
        "031f94d744af4c0f9ea6c24080e16449": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c30d73c61b434242a34737be1e50c487",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a68e69ee46064a8e90463a81df508c57",
            "value": 898823
          }
        },
        "2e1525a0f7ca41d9a74be54d9bc1a9c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea18d8858cc40e09fbc68e0551da708",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ed9069916c1a4cf1b5693b4ab86c5c30",
            "value": "â€‡899k/899kâ€‡[00:00&lt;00:00,â€‡19.6MB/s]"
          }
        },
        "8aa790f4c7274754bc1f8ad69bedc869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "547ccf5eb23840b48cb34a5ff1c1c12c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b5ca83609e499285d2c7a02b8e811b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c30d73c61b434242a34737be1e50c487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a68e69ee46064a8e90463a81df508c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aea18d8858cc40e09fbc68e0551da708": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed9069916c1a4cf1b5693b4ab86c5c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "908b4dd4a17641c28c13ff81c145f6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_52ab1dd2b73b49948c290d455bfc00f1",
              "IPY_MODEL_8808959cc4a346e7aa3c2d5665fe0221",
              "IPY_MODEL_f995d686a0cd423d91eddc0bba883d5a"
            ],
            "layout": "IPY_MODEL_af9aa40682ca4c10903d8091a15995e8"
          }
        },
        "52ab1dd2b73b49948c290d455bfc00f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_932db13661364d69bd6ef1b830988d6d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2747a6ff520c44cb86db4ed41ef4a6a1",
            "value": "merges.txt:â€‡100%"
          }
        },
        "8808959cc4a346e7aa3c2d5665fe0221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86c5297b3cee45aebf6d4a98639190eb",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac5d70dd1f5e4f7f82cdff36d98a3776",
            "value": 456318
          }
        },
        "f995d686a0cd423d91eddc0bba883d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3777b8ad4fd44a42afb8d00e17adfb33",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_87fbc680170446978e5bdd376401dfc8",
            "value": "â€‡456k/456kâ€‡[00:00&lt;00:00,â€‡14.8MB/s]"
          }
        },
        "af9aa40682ca4c10903d8091a15995e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "932db13661364d69bd6ef1b830988d6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2747a6ff520c44cb86db4ed41ef4a6a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86c5297b3cee45aebf6d4a98639190eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac5d70dd1f5e4f7f82cdff36d98a3776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3777b8ad4fd44a42afb8d00e17adfb33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87fbc680170446978e5bdd376401dfc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bb16ce060d64e18a8b5065576638194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_981f9240bb76423a85f354f77c2e83ce",
              "IPY_MODEL_c1597e445a994bb381c37aef93a64708",
              "IPY_MODEL_3388014d82684a78845e5058174f5930"
            ],
            "layout": "IPY_MODEL_199a74287aec4cb49ea1a974c667c61c"
          }
        },
        "981f9240bb76423a85f354f77c2e83ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b98b3327dad4e89b5acb9e91160fc7f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2d6836e1b7fd4acd9a69d4eb74765f04",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "c1597e445a994bb381c37aef93a64708": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e306bef984ae43e7a83c6b11ca63aa2f",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cbfcbab16fc44d84994d486b294d8f5d",
            "value": 1355863
          }
        },
        "3388014d82684a78845e5058174f5930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ba6a4bfac62442fb1dc71f87e4d44c3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a9b4ba346ddc44578a665daed4ca7502",
            "value": "â€‡1.36M/1.36Mâ€‡[00:00&lt;00:00,â€‡3.14MB/s]"
          }
        },
        "199a74287aec4cb49ea1a974c667c61c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b98b3327dad4e89b5acb9e91160fc7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d6836e1b7fd4acd9a69d4eb74765f04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e306bef984ae43e7a83c6b11ca63aa2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbfcbab16fc44d84994d486b294d8f5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ba6a4bfac62442fb1dc71f87e4d44c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9b4ba346ddc44578a665daed4ca7502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31608376d9764444a02d602a1d9e2842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b994bf776f9f442a9adbd9d5de79c6ab",
              "IPY_MODEL_308d58cdd8df4233bc7239b1a2b7dae1",
              "IPY_MODEL_9ba9ea4ce63f47e0957f4ab19dcb11d4"
            ],
            "layout": "IPY_MODEL_9df96911ee5343449442391529539b96"
          }
        },
        "b994bf776f9f442a9adbd9d5de79c6ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_986c49bc9d774eea8a78af7ad498e3f0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8339a54fb327497fa950fc9bdbc6286b",
            "value": "config.json:â€‡100%"
          }
        },
        "308d58cdd8df4233bc7239b1a2b7dae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd98c4cd16314dd5ac9fedc38f47a285",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_391ed6f18e52470a8dab64159cb9c9fe",
            "value": 481
          }
        },
        "9ba9ea4ce63f47e0957f4ab19dcb11d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc8b632e81de4a959fd032d43a54a7fa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_48fee6dc0a4043fcb85ac47f6895a78c",
            "value": "â€‡481/481â€‡[00:00&lt;00:00,â€‡10.7kB/s]"
          }
        },
        "9df96911ee5343449442391529539b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "986c49bc9d774eea8a78af7ad498e3f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8339a54fb327497fa950fc9bdbc6286b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd98c4cd16314dd5ac9fedc38f47a285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "391ed6f18e52470a8dab64159cb9c9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc8b632e81de4a959fd032d43a54a7fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48fee6dc0a4043fcb85ac47f6895a78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e10cc7fe1de42ed9e280cdf34233fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0387c9a275fe4495ae4d6e866d6b6247",
              "IPY_MODEL_de476d0cba9742d09041b3491e950f12",
              "IPY_MODEL_56b6bba97ddb47efa9666b7985d11fe3"
            ],
            "layout": "IPY_MODEL_8881388a0b2a4e47b60254486852ac97"
          }
        },
        "0387c9a275fe4495ae4d6e866d6b6247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ff9ef2d39b34e6eaaf567655365820d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0573830ebf9e49cc9597026103111104",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "de476d0cba9742d09041b3491e950f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d96934f18f724573aa4467cdcd11c507",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c26788e8407042c59b8cff0382a50757",
            "value": 498818054
          }
        },
        "56b6bba97ddb47efa9666b7985d11fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b295d763b05548c694e99b191e89c1bf",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c3e0261c6289472eac5a9261a7e50096",
            "value": "â€‡499M/499Mâ€‡[00:03&lt;00:00,â€‡148MB/s]"
          }
        },
        "8881388a0b2a4e47b60254486852ac97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ff9ef2d39b34e6eaaf567655365820d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0573830ebf9e49cc9597026103111104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d96934f18f724573aa4467cdcd11c507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c26788e8407042c59b8cff0382a50757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b295d763b05548c694e99b191e89c1bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e0261c6289472eac5a9261a7e50096": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}